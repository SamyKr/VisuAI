//
//  CameraManager.swift (Version avec LiDAR)
//  test
//
//  Created by Samy üìç on 18/06/2025.
//  Updated with LiDAR integration - 19/06/2025
//

import AVFoundation
import Vision
import SwiftUI

// Mise √† jour du protocole pour inclure la distance
protocol CameraManagerDelegate {
    func didDetectObjects(_ detections: [(rect: CGRect, label: String, confidence: Float, distance: Float?)])
}

class CameraManager: NSObject, ObservableObject {
    @Published var isRunning = false
    @Published var hasPermission = false
    @Published var currentFPS: Double = 0.0
    @Published var isLiDAREnabled = false
    @Published var lidarAvailable = false
    
    var delegate: CameraManagerDelegate?
    
    private let captureSession = AVCaptureSession()
    private let videoDataOutput = AVCaptureVideoDataOutput()
    private let depthDataOutput = AVCaptureDepthDataOutput()
    private var outputSynchronizer: AVCaptureDataOutputSynchronizer?
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")
    private var previewLayer: AVCaptureVideoPreviewLayer?
    
    private let objectDetectionManager = ObjectDetectionManager()
    private let lidarManager = LiDARManager()
    
    // Configuration des skip frames
    private var skipFrameCount = 5
    private var frameCounter = 0
    
    // Variables pour la synchronisation des donn√©es
    private var lastImageBuffer: CVPixelBuffer?
    private var lastDepthData: AVDepthData?
    private var imageSize: CGSize = .zero
    
    override init() {
        super.init()
        
        // V√©rifier la disponibilit√© du LiDAR
        lidarAvailable = lidarManager.isAvailable()
        
        setupCaptureSession()
        
        print("üé• CameraManager initialis√©")
        print("üìè LiDAR disponible: \(lidarAvailable ? "‚úÖ" : "‚ùå")")
    }
    
    func requestPermission() {
        AVCaptureDevice.requestAccess(for: .video) { granted in
            DispatchQueue.main.async {
                self.hasPermission = granted
            }
        }
    }
    
    func startSession() {
        guard hasPermission else {
            requestPermission()
            return
        }
        
        sessionQueue.async {
            if !self.captureSession.isRunning {
                self.captureSession.startRunning()
                DispatchQueue.main.async {
                    self.isRunning = true
                }
            }
        }
    }
    
    func stopSession() {
        sessionQueue.async {
            if self.captureSession.isRunning {
                self.captureSession.stopRunning()
                DispatchQueue.main.async {
                    self.isRunning = false
                }
            }
        }
    }
    
    func getPreviewLayer() -> AVCaptureVideoPreviewLayer {
        if previewLayer == nil {
            previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
            previewLayer?.videoGravity = .resizeAspectFill
        }
        return previewLayer!
    }
    
    // MARK: - LiDAR Controls
    func enableLiDAR() -> Bool {
        guard lidarAvailable else {
            print("‚ùå LiDAR non disponible")
            return false
        }
        
        let success = lidarManager.enableDepthCapture()
        if success {
            DispatchQueue.main.async {
                self.isLiDAREnabled = true
            }
            print("‚úÖ LiDAR activ√©")
        }
        return success
    }
    
    func disableLiDAR() {
        lidarManager.disableDepthCapture()
        DispatchQueue.main.async {
            self.isLiDAREnabled = false
        }
        print("‚èπÔ∏è LiDAR d√©sactiv√©")
    }
    
    func toggleLiDAR() -> Bool {
        if isLiDAREnabled {
            disableLiDAR()
            return false
        } else {
            return enableLiDAR()
        }
    }
    
    // MARK: - Statistics
    func getPerformanceStats() -> String {
        var stats = objectDetectionManager.getPerformanceStats()
        
        if lidarAvailable {
            stats += "\n\n" + lidarManager.getLiDARStats()
        }
        
        return stats
    }
    
    func resetPerformanceStats() {
        objectDetectionManager.resetStats()
        lidarManager.resetStats()
    }
    
    // MARK: - Configuration
    func setSkipFrames(_ count: Int) {
        skipFrameCount = max(0, count)
        print("‚öôÔ∏è Skip frames d√©fini √†: \(skipFrameCount)")
    }
    
    func getSkipFrames() -> Int {
        return skipFrameCount
    }
    
    func setActiveClasses(_ classes: [String]) {
        objectDetectionManager.setActiveClasses(classes)
    }
    
    func getActiveClasses() -> [String] {
        return objectDetectionManager.getActiveClasses()
    }
    
    // MARK: - Setup
    private func setupCaptureSession() {
        sessionQueue.async {
            self.captureSession.beginConfiguration()
            
            // Configuration de la session pour de meilleures performances
            if self.captureSession.canSetSessionPreset(.hd1920x1080) {
                self.captureSession.sessionPreset = .hd1920x1080
            }
            
            // Ajouter l'entr√©e vid√©o avec support LiDAR si disponible
            guard let videoDevice = self.getBestCameraDevice(),
                  let videoDeviceInput = try? AVCaptureDeviceInput(device: videoDevice),
                  self.captureSession.canAddInput(videoDeviceInput) else {
                print("‚ùå Impossible de configurer l'entr√©e vid√©o")
                return
            }
            
            self.captureSession.addInput(videoDeviceInput)
            
            // Stocker la taille de l'image pour les calculs de distance
            let dimensions = CMVideoFormatDescriptionGetDimensions(videoDevice.activeFormat.formatDescription)
            self.imageSize = CGSize(width: Int(dimensions.width), height: Int(dimensions.height))
            
            // Configurer la sortie vid√©o
            if self.captureSession.canAddOutput(self.videoDataOutput) {
                self.captureSession.addOutput(self.videoDataOutput)
                
                self.videoDataOutput.videoSettings = [
                    kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
                ]
                
                // Configuration pour de meilleures performances
                self.videoDataOutput.alwaysDiscardsLateVideoFrames = true
            }
            
            // Configurer la sortie de profondeur si LiDAR disponible
            if self.lidarAvailable && self.captureSession.canAddOutput(self.depthDataOutput) {
                self.captureSession.addOutput(self.depthDataOutput)
                
                // Connecter la sortie de profondeur √† l'entr√©e vid√©o
                if let connection = self.depthDataOutput.connection(with: .depthData) {
                    connection.isEnabled = true
                }
                
                // Configuration du format de profondeur
                if let depthFormat = self.getBestDepthFormat(for: videoDevice) {
                    try? videoDevice.lockForConfiguration()
                    videoDevice.activeDepthDataFormat = depthFormat
                    videoDevice.unlockForConfiguration()
                    print("‚úÖ Format de profondeur configur√©: \(depthFormat)")
                }
                
                print("‚úÖ Sortie de profondeur LiDAR configur√©e")
            }
            
            // Configurer le synchronizer pour coordonner les donn√©es
            self.configureSynchronizer()
            
            self.captureSession.commitConfiguration()
            print("‚úÖ Session de capture configur√©e avec LiDAR: \(self.lidarAvailable)")
        }
    }
    
    private func getBestCameraDevice() -> AVCaptureDevice? {
        // Essayer d'abord la cam√©ra avec LiDAR
        if lidarAvailable {
            if let lidarDevice = AVCaptureDevice.default(.builtInLiDARDepthCamera, for: .video, position: .back) {
                print("‚úÖ Utilisation de la cam√©ra LiDAR")
                return lidarDevice
            }
        }
        
        // Sinon, utiliser la cam√©ra standard
        return AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back)
    }
    
    private func getBestDepthFormat(for device: AVCaptureDevice) -> AVCaptureDevice.Format? {
        let depthFormats = device.activeFormat.supportedDepthDataFormats
        
        // Chercher un format 640x480 pour de bonnes performances
        let preferredDepthFormat = depthFormats.first { format in
            let dimensions = CMVideoFormatDescriptionGetDimensions(format.formatDescription)
            return dimensions.width == 640 && dimensions.height == 480
        }
        
        return preferredDepthFormat ?? depthFormats.first
    }
    
    private func configureSynchronizer() {
        // Cr√©er le synchronizer APR√àS que les outputs soient ajout√©s √† la session
        if lidarAvailable {
            outputSynchronizer = AVCaptureDataOutputSynchronizer(dataOutputs: [videoDataOutput, depthDataOutput])
            outputSynchronizer?.setDelegate(self, queue: DispatchQueue(label: "sync.processing.queue"))
            print("‚úÖ Synchronizer configur√© avec LiDAR")
        } else {
            // Mode sans LiDAR - utiliser seulement le delegate vid√©o
            videoDataOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "video.processing.queue"))
            print("‚úÖ Mode vid√©o seule configur√© (pas de LiDAR)")
        }
    }
}

// MARK: - AVCaptureDataOutputSynchronizerDelegate (avec LiDAR)
extension CameraManager: AVCaptureDataOutputSynchronizerDelegate {
    func dataOutputSynchronizer(_ synchronizer: AVCaptureDataOutputSynchronizer,
                               didOutput synchronizedDataCollection: AVCaptureSynchronizedDataCollection) {
        
        // Syst√®me de skip frames
        frameCounter += 1
        guard frameCounter % (skipFrameCount + 1) == 0 else { return }
        
        // R√©cup√©rer les donn√©es vid√©o
        guard let syncedVideoData = synchronizedDataCollection.synchronizedData(for: videoDataOutput) as? AVCaptureSynchronizedSampleBufferData,
              !syncedVideoData.sampleBufferWasDropped,
              let pixelBuffer = CMSampleBufferGetImageBuffer(syncedVideoData.sampleBuffer) else {
            return
        }
        
        // R√©cup√©rer les donn√©es de profondeur si disponibles
        var depthData: AVDepthData?
        if lidarAvailable && isLiDAREnabled,
           let syncedDepthData = synchronizedDataCollection.synchronizedData(for: depthDataOutput) as? AVCaptureSynchronizedDepthData,
           !syncedDepthData.depthDataWasDropped {
            depthData = syncedDepthData.depthData
            
            // Traiter les donn√©es de profondeur
            lidarManager.processDepthData(syncedDepthData.depthData)
        }
        
        // Stocker pour utilisation dans les calculs de distance
        lastImageBuffer = pixelBuffer
        lastDepthData = depthData
        
        // Effectuer la d√©tection d'objets avec donn√©es LiDAR
        objectDetectionManager.detectObjectsWithLiDAR(
            in: pixelBuffer,
            depthData: depthData,
            lidarManager: lidarManager,
            imageSize: imageSize
        ) { [weak self] detections, inferenceTime in
            DispatchQueue.main.async {
                self?.currentFPS = 1000.0 / inferenceTime
                self?.delegate?.didDetectObjects(detections)
            }
        }
    }
}

// MARK: - AVCaptureVideoDataOutputSampleBufferDelegate (sans LiDAR)
extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        
        // Ne traiter que si pas de synchronizer (mode sans LiDAR)
        guard outputSynchronizer == nil else { return }
        
        // Syst√®me de skip frames configurable
        frameCounter += 1
        guard frameCounter % (skipFrameCount + 1) == 0 else { return }
        
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        
        // Effectuer la d√©tection d'objets sans LiDAR (m√©thode legacy)
        objectDetectionManager.detectObjects(in: pixelBuffer) { [weak self] detections, inferenceTime in
            DispatchQueue.main.async {
                // Mettre √† jour le FPS pour l'affichage
                self?.currentFPS = 1000.0 / inferenceTime
                
                // Convertir au nouveau format avec distance nil
                let detectionsWithDistance = detections.map {
                    (rect: $0.rect, label: $0.label, confidence: $0.confidence, distance: nil as Float?)
                }
                
                // Notifier le d√©l√©gu√© des d√©tections
                self?.delegate?.didDetectObjects(detectionsWithDistance)
            }
        }
    }
}
