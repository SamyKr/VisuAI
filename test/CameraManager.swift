//
//  CameraManager.swift
//  VizAI Vision
//
//  R√îLE CENTRAL DANS L'ARCHITECTURE:
//  CameraManager est le C≈íUR du syst√®me de d√©tection - il orchestre tous les composants:
//
//  üì± CAPTURE VID√âO:
//  - Gestion compl√®te AVCaptureSession (cam√©ra + LiDAR si disponible)
//  - Configuration optimis√©e pour d√©tection IA (HD 1920x1080, 60fps)
//  - Synchronisation flux vid√©o/profondeur pour mesures de distance pr√©cises
//
//  ü§ñ INTELLIGENCE ARTIFICIELLE:
//  - Interface principale avec ObjectDetectionManager (YOLOv11)
//  - Orchestration d√©tection + tracking + scoring d'importance
//  - Gestion liste objets actifs/ignor√©s et classes dangereuses
//
//  üó£Ô∏è SYST√àME VOCAL ET HAPTIQUE:
//  - Connection directe avec VoiceSynthesisManager pour alertes critiques
//  - Contr√¥le HapticManager pour vibrations de proximit√©
//  - Transmission distance critique et objets dangereux
//
//  üìè LiDAR ET DISTANCES:
//  - Activation/d√©sactivation capteur profondeur
//  - Int√©gration LiDARManager pour mesures pr√©cises
//  - Calculs de proximit√© pour alertes s√©curit√©
//
//  üéØ INTERFACE UTILISATEUR:
//  - Delegate pattern pour communication avec DetectionView
//  - M√©thodes publiques pour tous les contr√¥les UI
//  - Gestion permissions et √©tats de session
//
//  FLUX DE DONN√âES:
//  Cam√©ra ‚Üí CameraManager ‚Üí ObjectDetection ‚Üí Tracking ‚Üí VoiceSynthesis/Haptic ‚Üí UI

import AVFoundation
import Vision
import SwiftUI

// MARK: - Protocol de Communication avec UI
protocol CameraManagerDelegate {
    /// Transmet les d√©tections enrichies avec tracking et distance √† l'interface
    /// - Parameter detections: Array des objets d√©tect√©s avec infos compl√®tes
    func didDetectObjects(_ detections: [(rect: CGRect, label: String, confidence: Float, distance: Float?, trackingInfo: (id: Int, color: UIColor, opacity: Double))])
}

// MARK: - Gestionnaire Principal Cam√©ra et D√©tection
class CameraManager: NSObject, ObservableObject {
    
    // MARK: - √âtats Publics Observables
    @Published var isRunning = false
    @Published var hasPermission = false
    @Published var currentFPS: Double = 0.0
    @Published var isLiDAREnabled = false
    @Published var lidarAvailable = false
    
    var delegate: CameraManagerDelegate?
    
    // MARK: - Composants Syst√®me Cam√©ra
    private let captureSession = AVCaptureSession()
    private let videoDataOutput = AVCaptureVideoDataOutput()
    private let depthDataOutput = AVCaptureDepthDataOutput()
    private var outputSynchronizer: AVCaptureDataOutputSynchronizer?
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")
    private var previewLayer: AVCaptureVideoPreviewLayer?
    
    // MARK: - Gestionnaires Sp√©cialis√©s
    private let objectDetectionManager = ObjectDetectionManager()
    private let lidarManager = LiDARManager()
    private let hapticManager = HapticManager()
    private var voiceSynthesisManager: VoiceSynthesisManager?
    
    // MARK: - Configuration Performance
    private var skipFrameCount = 1 // Nombre de frames √† ignorer (performance)
    private var frameCounter = 0   // Compteur pour skip frames
    
    // MARK: - Variables de Synchronisation
    private var lastImageBuffer: CVPixelBuffer?
    private var lastDepthData: AVDepthData?
    private var imageSize: CGSize = .zero
    
    // MARK: - Initialisation
    override init() {
        super.init()
        
        lidarAvailable = lidarManager.isAvailable()
        setupCaptureSession()
    }
    
    // MARK: - Gestion Permissions
    
    /// Demande l'autorisation d'acc√®s √† la cam√©ra
    func requestPermission() {
        AVCaptureDevice.requestAccess(for: .video) { granted in
            DispatchQueue.main.async {
                self.hasPermission = granted
            }
        }
    }
    
    // MARK: - Contr√¥le Session Cam√©ra
    
    /// D√©marre la session de capture vid√©o
    func startSession() {
        guard hasPermission else {
            requestPermission()
            return
        }
        
        sessionQueue.async {
            if !self.captureSession.isRunning {
                self.captureSession.startRunning()
                DispatchQueue.main.async {
                    self.isRunning = true
                }
            }
        }
    }
    
    /// Arr√™te la session de capture vid√©o
    func stopSession() {
        sessionQueue.async {
            if self.captureSession.isRunning {
                self.captureSession.stopRunning()
                DispatchQueue.main.async {
                    self.isRunning = false
                }
            }
        }
    }
    
    /// Fournit la couche de pr√©visualisation pour l'affichage UI
    /// - Returns: AVCaptureVideoPreviewLayer configur√©e
    func getPreviewLayer() -> AVCaptureVideoPreviewLayer {
        if previewLayer == nil {
            previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
            previewLayer?.videoGravity = .resizeAspectFill
        }
        return previewLayer!
    }
    
    // MARK: - Interface VoiceSynthesisManager
    
    /// Connecte le gestionnaire de synth√®se vocale pour les alertes
    /// - Parameter manager: Instance VoiceSynthesisManager
    func setVoiceSynthesisManager(_ manager: VoiceSynthesisManager) {
        self.voiceSynthesisManager = manager
    }
    
    /// Met √† jour la distance critique pour les alertes vocales
    /// - Parameter distance: Distance en m√®tres (0.5-10m)
    func updateCriticalDistance(_ distance: Float) {
        voiceSynthesisManager?.updateCriticalDistance(distance)
    }
    
    /// Met √† jour la liste des objets consid√©r√©s comme dangereux
    /// - Parameter dangerousObjects: Set des types d'objets dangereux
    func updateDangerousObjects(_ dangerousObjects: Set<String>) {
        voiceSynthesisManager?.updateDangerousObjects(dangerousObjects)
    }
    
    // MARK: - Contr√¥les Tracking
    
    /// R√©initialise le syst√®me de tracking des objets
    func resetTracking() {
        objectDetectionManager.resetTracking()
    }
    
    /// Obtient les statistiques d√©taill√©es du tracking
    /// - Returns: String format√© avec les stats
    func getTrackingStats() -> String {
        return objectDetectionManager.getTrackingStats()
    }
    
    // MARK: - Contr√¥les Vibrations Haptiques
    
    /// Active/d√©sactive les alertes de proximit√© par vibration
    /// - Parameter enabled: √âtat des alertes
    func enableProximityAlerts(_ enabled: Bool) {
        hapticManager.enableProximityAlerts(enabled)
    }
    
    func isProximityAlertsEnabled() -> Bool {
        return hapticManager.isProximityAlertsEnabled()
    }
    
    /// Configure la distance de danger pour vibrations
    /// - Parameter distance: Distance en m√®tres
    func setDangerDistance(_ distance: Float) {
        hapticManager.setDangerDistance(distance)
    }
    
    func getDangerDistance() -> Float {
        return hapticManager.getDangerDistance()
    }
    
    /// Configure la distance d'avertissement pour vibrations
    /// - Parameter distance: Distance en m√®tres
    func setWarningDistance(_ distance: Float) {
        hapticManager.setWarningDistance(distance)
    }
    
    func getWarningDistance() -> Float {
        return hapticManager.getWarningDistance()
    }
    
    /// D√©finit la plage d'intensit√© des vibrations
    /// - Parameters:
    ///   - min: Intensit√© minimale (0.0-1.0)
    ///   - max: Intensit√© maximale (0.0-1.0)
    func setIntensityRange(min: Float, max: Float) {
        hapticManager.setIntensityRange(min: min, max: max)
    }
    
    func getIntensityRange() -> (min: Float, max: Float) {
        return hapticManager.getIntensityRange()
    }
    
    /// Active/d√©sactive les vibrations gradu√©es selon la distance
    /// - Parameter enabled: √âtat des vibrations gradu√©es
    func enableGraduatedVibrations(_ enabled: Bool) {
        hapticManager.enableGraduatedVibrations(enabled)
    }
    
    func isGraduatedVibrationsEnabled() -> Bool {
        return hapticManager.isGraduatedVibrationsEnabled()
    }
    
    /// Active/d√©sactive la fr√©quence gradu√©e des vibrations
    /// - Parameter enabled: √âtat de la fr√©quence gradu√©e
    func enableGraduatedFrequency(_ enabled: Bool) {
        hapticManager.enableGraduatedFrequency(enabled)
    }
    
    func isGraduatedFrequencyEnabled() -> Bool {
        return hapticManager.isGraduatedFrequencyEnabled()
    }
    
    /// Configure la plage de fr√©quence des vibrations
    /// - Parameters:
    ///   - minCooldown: D√©lai minimum entre vibrations (proche)
    ///   - maxCooldown: D√©lai maximum entre vibrations (loin)
    func setFrequencyRange(minCooldown: TimeInterval, maxCooldown: TimeInterval) {
        hapticManager.setFrequencyRange(minCooldown: minCooldown, maxCooldown: maxCooldown)
    }
    
    func getFrequencyRange() -> (minCooldown: TimeInterval, maxCooldown: TimeInterval) {
        return hapticManager.getFrequencyRange()
    }
    
    // MARK: - Feedback Haptique Manuel
    
    /// Joue un feedback de succ√®s
    func playSuccessFeedback() {
        hapticManager.playSuccessFeedback()
    }
    
    /// Joue un feedback de s√©lection
    func playSelectionFeedback() {
        hapticManager.playSelectionFeedback()
    }
    
    /// Test vibration de danger avec intensit√© personnalis√©e
    /// - Parameter intensity: Intensit√© (0.0-1.0), d√©faut 1.0
    func testDangerVibration(intensity: Float = 1.0) {
        hapticManager.testDangerVibration(customIntensity: intensity)
    }
    
    /// Test vibration d'avertissement avec intensit√© personnalis√©e
    /// - Parameter intensity: Intensit√© (0.0-1.0), d√©faut 0.7
    func testWarningVibration(intensity: Float = 0.7) {
        hapticManager.testWarningVibration(customIntensity: intensity)
    }
    
    // MARK: - Contr√¥les LiDAR
    
    /// Active le capteur LiDAR si disponible
    /// - Returns: true si activation r√©ussie
    func enableLiDAR() -> Bool {
        guard lidarAvailable else { return false }
        
        let success = lidarManager.enableDepthCapture()
        if success {
            DispatchQueue.main.async {
                self.isLiDAREnabled = true
            }
        }
        return success
    }
    
    /// D√©sactive le capteur LiDAR
    func disableLiDAR() {
        lidarManager.disableDepthCapture()
        DispatchQueue.main.async {
            self.isLiDAREnabled = false
        }
    }
    
    /// Bascule l'√©tat du LiDAR
    /// - Returns: Nouvel √©tat (true = activ√©)
    func toggleLiDAR() -> Bool {
        if isLiDAREnabled {
            disableLiDAR()
            return false
        } else {
            return enableLiDAR()
        }
    }
    
    // MARK: - Objets Importants et Statistiques
    
    /// Obtient les objets les plus importants selon leur score
    /// - Parameter maxCount: Nombre maximum d'objets √† retourner
    /// - Returns: Array des objets avec leurs scores
    func getTopImportantObjects(maxCount: Int = 5) -> [(object: TrackedObject, score: Float)] {
        return objectDetectionManager.getTopImportantObjects(maxCount: maxCount)
    }
    
   
    
    /// Remet √† z√©ro toutes les statistiques
    func resetPerformanceStats() {
        objectDetectionManager.resetStats()
        lidarManager.resetStats()
        hapticManager.resetStats()
    }
    
    // MARK: - Configuration Performance
    
    /// Configure le nombre de frames √† ignorer pour optimiser les performances
    /// - Parameter count: Nombre de frames √† skip (0 = aucun skip)
    func setSkipFrames(_ count: Int) {
        skipFrameCount = max(0, count)
    }
    
    func getSkipFrames() -> Int {
        return skipFrameCount
    }
    
    // MARK: - Gestion Classes d'Objets
    
    /// D√©finit les classes d'objets √† d√©tecter (autres seront ignor√©es)
    /// - Parameter classes: Set des noms de classes √† activer
    func setEnabledClasses(_ classes: Set<String>) {
        objectDetectionManager.setEnabledClasses(classes)
    }
    
    /// Ajoute une classe √† la liste des objets ignor√©s
    /// - Parameter className: Nom de la classe √† ignorer
    func addIgnoredClass(_ className: String) {
        objectDetectionManager.addIgnoredClass(className)
    }
    
    /// Retire une classe de la liste des objets ignor√©s
    /// - Parameter className: Nom de la classe √† r√©activer
    func removeIgnoredClass(_ className: String) {
        objectDetectionManager.removeIgnoredClass(className)
    }
    
    /// Obtient la liste des classes actuellement ignor√©es
    /// - Returns: Array des noms de classes ignor√©es
    func getIgnoredClasses() -> [String] {
        return objectDetectionManager.getIgnoredClasses()
    }
    
    /// Vide la liste des classes ignor√©es (r√©active tout)
    func clearIgnoredClasses() {
        objectDetectionManager.clearIgnoredClasses()
    }
    
    /// Obtient toutes les classes disponibles dans le mod√®le
    /// - Returns: Array des 49 classes support√©es
    func getAvailableClasses() -> [String] {
        return objectDetectionManager.getAvailableClasses()
    }
    
    /// Acc√®s statique aux classes du mod√®le YOLOv11
    /// - Returns: Array des 49 classes du mod√®le
    static func getAllModelClasses() -> [String] {
        return ObjectDetectionManager.getAllModelClasses()
    }
    
    // MARK: - Configuration Session Cam√©ra
    
    /// Configure la session de capture avec support LiDAR optimal
    private func setupCaptureSession() {
        sessionQueue.async {
            self.captureSession.beginConfiguration()
            
            // Configuration haute r√©solution pour meilleure d√©tection IA
            if self.captureSession.canSetSessionPreset(.hd1920x1080) {
                self.captureSession.sessionPreset = .hd1920x1080
            }
            
            // Configuration entr√©e vid√©o avec support LiDAR
            guard let videoDevice = self.getBestCameraDevice(),
                  let videoDeviceInput = try? AVCaptureDeviceInput(device: videoDevice),
                  self.captureSession.canAddInput(videoDeviceInput) else {
                return
            }
            
            self.captureSession.addInput(videoDeviceInput)
            
            // Stockage taille image pour calculs de distance
            let dimensions = CMVideoFormatDescriptionGetDimensions(videoDevice.activeFormat.formatDescription)
            self.imageSize = CGSize(width: Int(dimensions.width), height: Int(dimensions.height))
            
            // Configuration sortie vid√©o optimis√©e
            if self.captureSession.canAddOutput(self.videoDataOutput) {
                self.captureSession.addOutput(self.videoDataOutput)
                
                self.videoDataOutput.videoSettings = [
                    kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
                ]
                
                self.videoDataOutput.alwaysDiscardsLateVideoFrames = true
            }
            
            // Configuration sortie profondeur LiDAR si disponible
            if self.lidarAvailable && self.captureSession.canAddOutput(self.depthDataOutput) {
                self.captureSession.addOutput(self.depthDataOutput)
                
                if let connection = self.depthDataOutput.connection(with: .depthData) {
                    connection.isEnabled = true
                }
                
                // Configuration format profondeur optimal
                if let depthFormat = self.getBestDepthFormat(for: videoDevice) {
                    try? videoDevice.lockForConfiguration()
                    videoDevice.activeDepthDataFormat = depthFormat
                    videoDevice.unlockForConfiguration()
                }
            }
            
            // Configuration synchronizer pour coordination vid√©o/profondeur
            self.configureSynchronizer()
            
            self.captureSession.commitConfiguration()
        }
    }
    
    /// S√©lectionne la meilleure cam√©ra disponible (LiDAR en priorit√©)
    /// - Returns: AVCaptureDevice optimal pour d√©tection
    private func getBestCameraDevice() -> AVCaptureDevice? {
        // Priorit√© √† la cam√©ra avec LiDAR si disponible
        if lidarAvailable {
            if let lidarDevice = AVCaptureDevice.default(.builtInLiDARDepthCamera, for: .video, position: .back) {
                return lidarDevice
            }
        }
        
        // Sinon cam√©ra standard arri√®re
        return AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back)
    }
    
    /// S√©lectionne le meilleur format de profondeur pour performances optimales
    /// - Parameter device: Device cam√©ra
    /// - Returns: Format de profondeur optimal (640x480 prioritaire)
    private func getBestDepthFormat(for device: AVCaptureDevice) -> AVCaptureDevice.Format? {
        let depthFormats = device.activeFormat.supportedDepthDataFormats
        
        // Recherche format 640x480 pour √©quilibre qualit√©/performance
        let preferredDepthFormat = depthFormats.first { format in
            let dimensions = CMVideoFormatDescriptionGetDimensions(format.formatDescription)
            return dimensions.width == 640 && dimensions.height == 480
        }
        
        return preferredDepthFormat ?? depthFormats.first
    }
    
    /// Configure le synchronizer pour coordination vid√©o/profondeur
    private func configureSynchronizer() {
        if lidarAvailable {
            // Mode LiDAR: synchronisation vid√©o + profondeur
            outputSynchronizer = AVCaptureDataOutputSynchronizer(dataOutputs: [videoDataOutput, depthDataOutput])
            outputSynchronizer?.setDelegate(self, queue: DispatchQueue(label: "sync.processing.queue"))
        } else {
            // Mode standard: vid√©o seule
            videoDataOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "video.processing.queue"))
        }
    }
}

// MARK: - Delegate Synchronization (Mode LiDAR)
extension CameraManager: AVCaptureDataOutputSynchronizerDelegate {
    
    /// Traite les donn√©es synchronis√©es vid√©o + profondeur LiDAR
    /// - Parameters:
    ///   - synchronizer: Synchronizer source
    ///   - synchronizedDataCollection: Donn√©es coordonn√©es vid√©o/profondeur
    func dataOutputSynchronizer(_ synchronizer: AVCaptureDataOutputSynchronizer,
                               didOutput synchronizedDataCollection: AVCaptureSynchronizedDataCollection) {
        
        // Syst√®me skip frames pour optimisation performance
        frameCounter += 1
        guard frameCounter % (skipFrameCount + 1) == 0 else { return }
        
        // Extraction donn√©es vid√©o
        guard let syncedVideoData = synchronizedDataCollection.synchronizedData(for: videoDataOutput) as? AVCaptureSynchronizedSampleBufferData,
              !syncedVideoData.sampleBufferWasDropped,
              let pixelBuffer = CMSampleBufferGetImageBuffer(syncedVideoData.sampleBuffer) else {
            return
        }
        
        // Extraction donn√©es profondeur si LiDAR actif
        var depthData: AVDepthData?
        if lidarAvailable && isLiDAREnabled,
           let syncedDepthData = synchronizedDataCollection.synchronizedData(for: depthDataOutput) as? AVCaptureSynchronizedDepthData,
           !syncedDepthData.depthDataWasDropped {
            depthData = syncedDepthData.depthData
            lidarManager.processDepthData(syncedDepthData.depthData)
        }
        
        // Stockage pour calculs de distance
        lastImageBuffer = pixelBuffer
        lastDepthData = depthData
        
        // Lancement d√©tection IA avec donn√©es LiDAR et tracking
        objectDetectionManager.detectObjectsWithLiDAR(
            in: pixelBuffer,
            depthData: depthData,
            lidarManager: lidarManager,
            imageSize: imageSize
        ) { [weak self] detections, inferenceTime in
            DispatchQueue.main.async {
                self?.currentFPS = 1000.0 / inferenceTime
                
                // V√©rification proximit√© pour vibrations
                let proximityDetections = detections.map {
                    (rect: $0.rect, label: $0.label, confidence: $0.confidence, distance: $0.distance)
                }
                self?.hapticManager.checkProximityAndAlert(detections: proximityDetections)
                
                // Transmission √† l'interface utilisateur
                self?.delegate?.didDetectObjects(detections)
            }
        }
    }
}

// MARK: - Delegate Video (Mode Standard)
extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    
    /// Traite les donn√©es vid√©o seules (sans LiDAR)
    /// - Parameters:
    ///   - output: Source de sortie
    ///   - sampleBuffer: Buffer vid√©o
    ///   - connection: Connection source
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        
        // Ne traiter que si pas de synchronizer (mode sans LiDAR)
        guard outputSynchronizer == nil else { return }
        
        // Syst√®me skip frames
        frameCounter += 1
        guard frameCounter % (skipFrameCount + 1) == 0 else { return }
        
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        
        // D√©tection IA sans LiDAR mais avec tracking
        objectDetectionManager.detectObjects(in: pixelBuffer) { [weak self] detections, inferenceTime in
            DispatchQueue.main.async {
                self?.currentFPS = 1000.0 / inferenceTime
                self?.delegate?.didDetectObjects(detections)
            }
        }
    }
}
