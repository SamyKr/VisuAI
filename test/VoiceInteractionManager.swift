import Foundation
import AVFoundation
import Speech
import UIKit

// MARK: - Enums et Structures
enum VoiceCommand: String, CaseIterable {
    case activate = "dis moi"
    case alternative1 = "dis-moi"
    case alternative2 = "√©coute"
    case alternative3 = "hey"

    static let activationPhrases = VoiceCommand.allCases.map { $0.rawValue }
}

enum QuestionType {
    case presence      // "Y a-t-il une voiture ?"
    case count         // "Combien de voitures ?"
    case location      // "O√π est la voiture ?"
    case description   // "Qu'est-ce qui est devant moi ?"
    case sceneOverview // "D√©cris la sc√®ne"
    case specific      // "O√π est le feu ?"
    case crossing      // "Est-ce que je peux traverser ?"
    case unknown
}

struct ParsedQuestion {
    let type: QuestionType
    let targetObject: String?
    let confidence: Float
    let originalText: String
}

struct SceneAnalysis {
    let totalObjects: Int
    let objectsByType: [String: Int]
    let objectsByZone: [String: [String]]
    let distances: [String: Float]
    let criticalObjects: [String]
    let navigationObjects: [String]
}

// MARK: - VoiceInteractionManager avec confiance totale en Apple
class VoiceInteractionManager: NSObject, ObservableObject {

    // MARK: - Configuration
    private let listeningTimeout: TimeInterval = 5.0
    private let activationTimeout: TimeInterval = 2.0
    private let emergencyTimeoutDuration: TimeInterval = 30.0  // Timeout d'urgence seulement
    private let maxRetryAttempts = 3
    private let retryDelay: TimeInterval = 2.0

    // üîí RECONNAISSANCE LOCALE UNIQUEMENT - Aucune donn√©e envoy√©e sur internet

    // MARK: - √âtat
    @Published var isListening = false
    @Published var isWaitingForQuestion = false
    @Published var lastRecognizedText = ""
    @Published var interactionEnabled = true

    // MARK: - Gestion d'erreurs
    private var currentRetryCount = 0
    private var lastErrorTime: Date?
    private var isRecovering = false
    private var speechAvailable = true

    // MARK: - Reconnaissance vocale
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "fr-FR"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()

    // MARK: - Audio
    private var beepPlayer: AVAudioPlayer?
    private var questionTimer: Timer?
    private var activationTimer: Timer?
    private var recoveryTimer: Timer?

    // MARK: - R√©solution du probl√®me isFinal
    private var lastPartialUpdate: Date?
    private var lastPartialResult: String = ""
    private var partialResultTimer: Timer?

    // MARK: - R√©f√©rences externes
    weak var voiceSynthesisManager: VoiceSynthesisManager?
    private var currentImportantObjects: [(object: TrackedObject, score: Float)] = []

    // MARK: - Dictionnaire de traduction invers√©e (COMPLET)
    private let objectTranslations: [String: [String]] = [
        // V√©hicules et usagers
        "person": ["personne", "personnes", "gens", "pi√©ton", "pi√©tons", "homme", "femme", "enfant", "individu"],
        "cyclist": ["cycliste", "cyclistes", "v√©lo", "cyclisme"],
        "motorcyclist": ["motocycliste", "motocyclistes", "motard", "motards"],
        "car": ["voiture", "voitures", "auto", "autos", "v√©hicule", "v√©hicules", "bagnole", "caisse", "automobile"],
        "truck": ["camion", "camions", "poids lourd", "poids lourds", "semi", "semi-remorque", "camionnette"],
        "bus": ["bus", "autobus", "car", "transport en commun"],
        "motorcycle": ["moto", "motos", "motocyclette", "motocyclettes", "scooter", "scooters", "deux-roues"],
        "bicycle": ["v√©lo", "v√©los", "bicyclette", "bicyclettes", "bike", "cycle"],
        "slow_vehicle": ["v√©hicule lent", "v√©hicule ralenti", "voiture lente"],
        "vehicle_group": ["groupe de v√©hicules", "convoi", "files de voitures"],
        "rail_vehicle": ["v√©hicule ferroviaire", "train", "tramway", "m√©tro"],
        "boat": ["bateau", "bateaux", "embarcation", "navire"],
        
        // Infrastructure routi√®re
        "sidewalk": ["trottoir", "trottoirs", "chauss√©e pi√©tonne"],
        "road": ["route", "routes", "rue", "rues", "chauss√©e", "voie", "avenue", "boulevard"],
        "crosswalk": ["passage pi√©ton", "passage pi√©tons", "passage clout√©", "zebra", "travers√©e"],
        "driveway": ["all√©e", "all√©es", "entr√©e", "acc√®s"],
        "bike_lane": ["piste cyclable", "voie cyclable", "bande cyclable"],
        "parking_area": ["zone de stationnement", "parking", "place de parking", "stationnement"],
        "rail_track": ["voie ferr√©e", "rails", "chemin de fer"],
        "service_lane": ["voie de service", "bande de service"],
        "curb": ["bordure", "bordures", "trottoir", "rebord"],
        
        // Barri√®res et obstacles
        "wall": ["mur", "murs", "muraille", "cloison"],
        "fence": ["cl√¥ture", "cl√¥tures", "grillage", "barri√®re"],
        "guard_rail": ["glissi√®re de s√©curit√©", "garde-corps", "barri√®re de s√©curit√©"],
        "temporary_barrier": ["barri√®re temporaire", "barri√®re de chantier", "obstacle temporaire"],
        "barrier_other": ["autre barri√®re", "obstacle", "barri√®re"],
        "barrier": ["barri√®re", "barri√®res", "obstacle", "obstacles"],
        "pole": ["poteau", "poteaux", "pilier", "piliers", "m√¢t", "borne"],
        
        // Signalisation et √©quipements
        "traffic_light": ["feu", "feux", "feu de circulation", "feux de circulation", "feu tricolore", "signal", "signalisation lumineuse"],
        "traffic_sign": ["panneau", "panneaux", "panneau de signalisation", "signalisation", "stop", "signal routier"],
        "street_light": ["lampadaire", "lampadaires", "√©clairage public", "r√©verb√®re"],
        "traffic_cone": ["c√¥ne", "c√¥nes", "plot", "balise"],
        
        // Mobilier urbain
        "bench": ["banc", "bancs", "si√®ge"],
        "trash_can": ["poubelle", "poubelles", "benne", "conteneur"],
        "fire_hydrant": ["bouche d'incendie", "borne incendie", "hydrant"],
        "mailbox": ["bo√Æte aux lettres", "bo√Æte postale", "courrier"],
        "parking_meter": ["parcm√®tre", "horodateur", "compteur parking"],
        "bike_rack": ["support √† v√©los", "rack v√©lo", "stationnement v√©lo"],
        "phone_booth": ["cabine t√©l√©phonique", "cabine", "t√©l√©phone public"],
        
        // √âl√©ments de voirie
        "pothole": ["nid-de-poule", "trou", "d√©faut chauss√©e"],
        "manhole": ["plaque d'√©gout", "bouche d'√©gout", "regard"],
        "catch_basin": ["regard d'√©gout", "avaloir", "grille d'√©vacuation"],
        "water_valve": ["vanne d'eau", "robinet", "valve"],
        "junction_box": ["bo√Ætier de jonction", "coffret √©lectrique", "bo√Ætier"],
        
        // Structures et environnement
        "building": ["b√¢timent", "b√¢timents", "immeuble", "immeubles", "maison", "maisons", "construction"],
        "bridge": ["pont", "ponts", "passerelle", "viaduc"],
        "tunnel": ["tunnel", "tunnels", "passage souterrain"],
        "garage": ["garage", "garages", "abri"],
        "vegetation": ["v√©g√©tation", "plante", "plantes", "verdure", "feuillage"],
        "water": ["eau", "rivi√®re", "lac", "√©tang", "cours d'eau"],
        "terrain": ["terrain", "sol", "surface", "ground"],
        "animals": ["animaux", "animal", "b√™te", "b√™tes"],
        
        // Objets compl√©mentaires d√©j√† pr√©sents
        "pedestrian crossing": ["passage pi√©ton", "passage pi√©tons", "passage clout√©", "zebra"],
        "tree": ["arbre", "arbres"],
        "light": ["lumi√®re", "lumi√®res", "√©clairage", "lampe", "lampes"]
    ]

    // MARK: - Mots-cl√©s pour les questions
    private func getPresenceKeywords() -> [String] {
        return ["y a-t-il", "ya-t-il", "est-ce qu'il y a", "il y a", "vois-tu", "d√©tectes-tu","tu vois"]
    }

    private func getCountKeywords() -> [String] {
        return ["combien", "nombre", "quantit√©"]
    }

    private func getLocationKeywords() -> [String] {
        return ["o√π", "ou", "position", "situ√©e", "situ√©", "place"]
    }

    private func getDescriptionKeywords() -> [String] {
        return ["qu'est-ce qui", "que vois-tu", "devant moi", "autour"]
    }

    private func getCrossingKeywords() -> [String] {
        return ["peux traverser", "puis traverser", "peut traverser", "traverser", "passer", "croiser", "s√ªr de traverser", "s√©curis√© pour traverser"]
    }

    private func getSceneKeywords() -> [String] {
        return ["d√©cris", "d√©cris la sc√®ne", "que se passe-t-il", "situation"]
    }

    private func getQuestionKeywords() -> [QuestionType: [String]] {
        return [
            .presence: getPresenceKeywords(),
            .count: getCountKeywords(),
            .location: getLocationKeywords(),
            .description: getDescriptionKeywords(),
            .sceneOverview: getSceneKeywords(),
            .crossing: getCrossingKeywords()
        ]
    }

    override init() {
        super.init()
        setupAudio()
        requestSpeechPermission()
        setupBeepSound()
        checkSpeechAvailability()
        print("üé§ VoiceInteractionManager initialis√© - Fait confiance au syst√®me Apple")
        print("üìö Dictionnaire d'objets: \(objectTranslations.count) types d'objets support√©s")
    }

    deinit {
        cleanupResources()
    }

    // MARK: - Configuration et nettoyage

    private func setupAudio() {
        do {
            let audioSession = AVAudioSession.sharedInstance()
            
            // ‚úÖ NOUVELLE CONFIGURATION : Support AirPods + Bluetooth
            try audioSession.setCategory(
                .playAndRecord,
                mode: .measurement,
                options: [
                    .duckOthers,
                    .allowBluetooth,           // ‚Üê NOUVEAU : Autoriser Bluetooth
                    .allowBluetoothA2DP,       // ‚Üê NOUVEAU : Autoriser AirPods/casques
                ]
            )
            
            try audioSession.setActive(false) // Commencer inactif
            
            // ‚úÖ NOUVEAU : Forcer la route intelligente D√àS LE D√âBUT
            let hasAirPods = audioSession.currentRoute.outputs.contains {
                $0.portType == .bluetoothA2DP || $0.portType == .bluetoothHFP
            }
            
            if hasAirPods {
                try audioSession.overrideOutputAudioPort(.none) // AirPods
                print("‚úÖ Route forc√©e vers AirPods d√®s l'init")
            } else {
                try audioSession.overrideOutputAudioPort(.speaker) // Haut-parleurs
                print("üîä Route forc√©e vers haut-parleurs d√®s l'init")
            }
            
            print("‚úÖ Configuration audio r√©ussie - AirPods support√©s")
            
            // üîç Debug : Afficher les routes audio disponibles
            printAvailableAudioRoutes()
            
        } catch {
            print("‚ùå Erreur configuration audio: \(error)")
        }
    } // ‚úÖ ACCOLADE MANQUANTE AJOUT√âE
    
    // ‚úÖ NOUVELLE M√âTHODE : Debug des routes audio
    private func printAvailableAudioRoutes() {
        let audioSession = AVAudioSession.sharedInstance()
        
        print("üì± Routes audio disponibles :")
        for output in audioSession.availableInputs ?? [] {
            print("  - Entr√©e : \(output.portName) (\(output.portType.rawValue))")
        }
        
        print("üîä Route de sortie actuelle :")
        for output in audioSession.currentRoute.outputs {
            print("  - Sortie : \(output.portName) (\(output.portType.rawValue))")
        }
        
        if audioSession.currentRoute.outputs.contains(where: { $0.portType == .bluetoothA2DP || $0.portType == .bluetoothHFP }) {
            print("‚úÖ AirPods/Bluetooth d√©tect√©s et actifs")
        } else {
            print("‚ö†Ô∏è Pas d'AirPods d√©tect√©s - v√©rifiez la connexion")
        }
    }

    private func checkSpeechAvailability() {
        guard let speechRecognizer = speechRecognizer else {
            speechAvailable = false
            interactionEnabled = false
            print("‚ùå SFSpeechRecognizer non initialis√©")
            return
        }

        speechAvailable = speechRecognizer.isAvailable

        if !speechAvailable {
            print("‚ùå Reconnaissance vocale non disponible")
            interactionEnabled = false
            return
        }

        // V√©rifier le support de la reconnaissance locale OBLIGATOIRE
        if #available(iOS 13.0, *) {
            if speechRecognizer.supportsOnDeviceRecognition {
                print("‚úÖ Reconnaissance vocale LOCALE pr√™te (100% priv√©, hors ligne)")
                interactionEnabled = true
            } else {
                print("‚ùå Reconnaissance locale non support√©e sur cet appareil")
                print("   L'interaction vocale sera d√©sactiv√©e pour pr√©server la vie priv√©e")
                interactionEnabled = false
            }
        } else {
            print("‚ùå iOS < 13.0 - reconnaissance locale requise non disponible")
            print("   Mise √† jour iOS recommand√©e pour l'interaction vocale")
            interactionEnabled = false
        }
    }

    private func cleanupResources() {
        stopListening()
        recoveryTimer?.invalidate()
        recoveryTimer = nil

        do {
            try AVAudioSession.sharedInstance().setActive(false)
        } catch {
            print("‚ùå Erreur d√©sactivation session audio: \(error)")
        }
    }

    // MARK: - Son d'activation
    
    private func setupBeepSound() {
        // üéµ NOUVEAU : Chercher d'abord le son personnalis√© de l'utilisateur
        let customSoundURL = getCustomSoundURL()
        
        do {
            if FileManager.default.fileExists(atPath: customSoundURL.path) {
                // Utiliser le son personnalis√©
                beepPlayer = try AVAudioPlayer(contentsOf: customSoundURL)
                print("‚úÖ Son personnalis√© charg√©: \(customSoundURL.lastPathComponent)")
            } else {
                // Fallback vers le bip g√©n√©r√©
                let beepURL = createBeepSound()
                beepPlayer = try AVAudioPlayer(contentsOf: beepURL)
                print("üîä Bip g√©n√©r√© utilis√© (son personnalis√© non trouv√©)")
            }
            
            beepPlayer?.prepareToPlay()
            beepPlayer?.volume = 1.0
        } catch {
            print("‚ùå Erreur cr√©ation son: \(error)")
        }
    }
    
    private func getCustomSoundURL() -> URL {

        let possibleBaseNames = [
            "indicvoca",           // ‚Üê NOUVEAU : Votre fichier !
        ]
        
        let possibleExtensions = ["wav", "mp3", "m4a"]
        
        // üîç DEBUG : Lister tous les fichiers audio dans le bundle
        debugBundleContents()
        
        // üè† PREMI√àRE PRIORIT√â : Chercher dans le bundle de l'app (plus simple)
        for baseName in possibleBaseNames {
            for ext in possibleExtensions {
                if let bundleURL = Bundle.main.url(forResource: baseName, withExtension: ext) {
                    print("üéµ Son personnalis√© trouv√© dans le bundle: \(baseName).\(ext)")
                    return bundleURL
                }
            }
        }
        
        // üìÅ DEUXI√àME PRIORIT√â : Chercher dans le dossier Documents
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        
        for baseName in possibleBaseNames {
            for ext in possibleExtensions {
                let soundURL = documentsPath.appendingPathComponent("\(baseName).\(ext)")
                if FileManager.default.fileExists(atPath: soundURL.path) {
                    print("üéµ Son personnalis√© trouv√© dans Documents: \(baseName).\(ext)")
                    return soundURL
                }
            }
        }
        
        print("‚ö†Ô∏è Aucun son personnalis√© trouv√©. Recherch√©:")
        print("   üì± Dans le bundle: \(possibleBaseNames.map { "\($0).wav/mp3/m4a" }.joined(separator: ", "))")
        print("   üìÅ Dans Documents: \(possibleBaseNames.map { "\($0).wav/mp3/m4a" }.joined(separator: ", "))")
        
        // Fallback : retourner un chemin dans Documents pour le bip g√©n√©r√©
        return documentsPath.appendingPathComponent("custom_beep.wav")
    }
    
    // üîç DEBUG : Fonction pour lister le contenu du bundle
    private func debugBundleContents() {
        print("üîç === DEBUG BUNDLE CONTENTS ===")
        
        // Lister tous les fichiers du bundle principal
        if let bundlePath = Bundle.main.resourcePath {
            do {
                let bundleContents = try FileManager.default.contentsOfDirectory(atPath: bundlePath)
                
                // Filtrer les fichiers audio
                let audioFiles = bundleContents.filter { file in
                    let ext = (file as NSString).pathExtension.lowercased()
                    return ["wav", "mp3", "m4a", "aiff", "caf"].contains(ext)
                }
                
                print("üì± Fichiers audio dans le bundle (\(audioFiles.count)) :")
                if audioFiles.isEmpty {
                    print("   ‚ùå Aucun fichier audio trouv√©")
                } else {
                    for file in audioFiles.sorted() {
                        print("   ‚úÖ \(file)")
                    }
                }
                
                // V√©rifier sp√©cifiquement indicvoca.wav
                if bundleContents.contains("indicvoca.wav") {
                    print("üéµ TROUV√â : indicvoca.wav est bien dans le bundle ! ‚úÖ")
                } else {
                    print("‚ùå indicvoca.wav NON TROUV√â dans le bundle")
                }
                
            } catch {
                print("‚ùå Erreur lecture bundle: \(error)")
            }
        }
        
        // Test direct de votre fichier
        if let indicvocaURL = Bundle.main.url(forResource: "indicvoca", withExtension: "wav") {
            print("üéØ Test direct: indicvoca.wav accessible √† \(indicvocaURL)")
        } else {
            print("üéØ Test direct: indicvoca.wav NON accessible via Bundle.main")
        }
        
        print("üîç === FIN DEBUG BUNDLE ===")
    }

    private func createBeepSound() -> URL {
        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
        let audioFilename = documentsPath.appendingPathComponent("interaction_beep.wav")

        if FileManager.default.fileExists(atPath: audioFilename.path) {
            return audioFilename
        }

        let sampleRate: Double = 44100
        let duration: Double = 0.3
        let frequency: Double = 880.0
        let amplitude: Float = 0.5

        let frameCount = UInt32(sampleRate * duration)
        let bytesPerFrame = 2
        let totalBytes = frameCount * UInt32(bytesPerFrame)

        var audioData = Data(count: Int(totalBytes))

        audioData.withUnsafeMutableBytes { (bytes: UnsafeMutableRawBufferPointer) in
            let samples = bytes.bindMemory(to: Int16.self)
            let frameCountInt = Int(frameCount)

            for i in 0..<frameCountInt {
                let timeValue = Double(i) / sampleRate
                let sinValue = sin(2.0 * Double.pi * frequency * timeValue)
                let scaledValue = amplitude * 32767.0 * Float(sinValue)
                let sample = Int16(scaledValue)
                samples[i] = sample
            }
        }

        try? audioData.write(to: audioFilename)
        return audioFilename
    }

    private func requestSpeechPermission() {
        SFSpeechRecognizer.requestAuthorization { [weak self] authStatus in
            DispatchQueue.main.async {
                switch authStatus {
                case .authorized:
                    print("‚úÖ Permission reconnaissance vocale accord√©e")
                    self?.interactionEnabled = self?.speechAvailable ?? false
                case .denied, .restricted, .notDetermined:
                    print("‚ùå Permission reconnaissance vocale refus√©e")
                    self?.interactionEnabled = false
                @unknown default:
                    self?.interactionEnabled = false
                }
            }
        }
    }

    // MARK: - Interface publique

    func setVoiceSynthesisManager(_ manager: VoiceSynthesisManager) {
        self.voiceSynthesisManager = manager
    }

    func updateImportantObjects(_ objects: [(object: TrackedObject, score: Float)]) {
        self.currentImportantObjects = objects
        print("üîÑ VoiceInteraction: Re√ßu \(objects.count) objets importants")
        for (index, item) in objects.enumerated() {
            print("   \(index + 1). #\(item.object.trackingNumber) \(item.object.label) (score: \(item.score))")
        }
    }

    /// V√©rifie si la reconnaissance locale est support√©e sur cet appareil
    func isLocalRecognitionSupported() -> Bool {
        if #available(iOS 13.0, *) {
            return speechRecognizer?.supportsOnDeviceRecognition ?? false
        }
        return false
    }

    /// Retourne la version iOS minimum requise pour l'interaction vocale
    func getMinimumIOSVersion() -> String {
        return "iOS 13.0+"
    }

    func startContinuousListening() {
        guard interactionEnabled && speechAvailable else {
            print("‚ùå Interaction vocale d√©sactiv√©e ou service indisponible")
            return
        }

        guard !isListening && !isRecovering else {
            print("‚ö†Ô∏è √âcoute d√©j√† active ou en r√©cup√©ration")
            return
        }

        print("üé§ Mode interaction vocale ACTIV√â (appuyez sur le bouton mic pour parler)")
        // Note: On n'√©coute PAS en continu, on attend l'activation manuelle
        currentRetryCount = 0
        lastRecognizedText = "Pr√™t - touchez le micro pour parler"
    }

    func stopContinuousListening() {
        stopListening()
        isRecovering = false
        recoveryTimer?.invalidate()
        recoveryTimer = nil
        lastRecognizedText = ""
        print("üé§ Mode interaction vocale D√âSACTIV√â")
    }

    /// D√©marre l'√©coute pour UNE question (appel√© par l'appui long)
    func startSingleQuestion() {
        guard interactionEnabled && speechAvailable else {
            voiceSynthesisManager?.speak("Interaction vocale non disponible")
            return
        }

        guard !isListening else {
            print("‚ö†Ô∏è √âcoute d√©j√† en cours")
            return
        }

        print("üé§ D√©marrage √©coute d'UNE question - Apple g√®re la finalisation")

        // üõë ARR√äT TOTAL DE TOUTE SYNTH√àSE VOCALE
        voiceSynthesisManager?.stopSpeaking()
        voiceSynthesisManager?.interruptForInteraction(reason: "Question utilisateur")

        // Attendre que l'audio se lib√®re compl√®tement
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            // Jouer le beep (maintenant personnalis√©)
            self?.playBeep()

            // Passer en mode question directement
            self?.isWaitingForQuestion = true

            // D√©lai adaptatif bas√© sur la dur√©e du son
            let soundDuration = self?.beepPlayer?.duration ?? 0.3
            let adaptiveDelay = max(soundDuration + 0.2, 0.5)

            // D√©marrer l'√©coute apr√®s le son + petit buffer
            DispatchQueue.main.asyncAfter(deadline: .now() + adaptiveDelay) { [weak self] in
                self?.startListening(forActivation: false)

                // üéØ TIMEOUT BEAUCOUP PLUS LONG - Juste s√©curit√© contre les blocages
                self?.questionTimer = Timer.scheduledTimer(withTimeInterval: self?.emergencyTimeoutDuration ?? 30.0, repeats: false) { _ in
                    self?.handleEmergencyTimeout()
                }
            }
        }
    }

    func toggleListening() {
        if isListening {
            stopContinuousListening()
        } else {
            startContinuousListening()
        }
    }

    // MARK: - M√©thodes publiques pour interaction directe

    func interruptForInteraction(reason: String = "Interaction utilisateur") {
        print("üõë Interruption pour interaction: \(reason)")
        voiceSynthesisManager?.interruptForInteraction(reason: reason)
    }

    func speakInteraction(_ text: String, priority: Int = 15) {
        voiceSynthesisManager?.speakInteraction(text)
        print("üé§ Message d'interaction envoy√©: '\(text)'")
    }

    func resumeAfterInteraction() {
        voiceSynthesisManager?.resumeAfterInteraction()
        print("‚ñ∂Ô∏è Reprise apr√®s interaction")
    }

    // MARK: - Reconnaissance vocale avec confiance totale en Apple

    private func startListening(forActivation: Bool = false) {
        guard let speechRecognizer = speechRecognizer, speechRecognizer.isAvailable else {
            print("‚ùå Reconnaissance vocale non disponible")
            handleSpeechError(NSError(domain: "SpeechRecognizer", code: -1, userInfo: [NSLocalizedDescriptionKey: "Service non disponible"]))
            return
        }

        // V√©rifier si on est en p√©riode de r√©cup√©ration
        if let lastError = lastErrorTime, Date().timeIntervalSince(lastError) < retryDelay {
            print("‚è≥ En attente avant nouvelle tentative...")
            scheduleRetry(forActivation: forActivation)
            return
        }

        stopListening() // Nettoyer toute session pr√©c√©dente

        // Activer la session audio
        do {
            try AVAudioSession.sharedInstance().setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            print("‚ùå Erreur activation session audio: \(error)")
            handleSpeechError(error)
            return
        }

        isListening = true

        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            handleSpeechError(NSError(domain: "SpeechRecognizer", code: -2, userInfo: [NSLocalizedDescriptionKey: "Impossible de cr√©er la requ√™te"]))
            return
        }

        // üîí RECONNAISSANCE LOCALE UNIQUEMENT üîí
        recognitionRequest.shouldReportPartialResults = true

        if #available(iOS 13.0, *) {
            // OBLIGATOIRE : Mode local seulement
            recognitionRequest.requiresOnDeviceRecognition = true
            print("‚úÖ Mode LOCAL forc√© (aucune donn√©e envoy√©e sur internet)")

            // Double v√©rification s√©curit√©
            if !speechRecognizer.supportsOnDeviceRecognition {
                print("‚ùå ERREUR : Mode local requis mais non support√©")
                handleSpeechError(NSError(domain: "SpeechRecognizer", code: -3, userInfo: [NSLocalizedDescriptionKey: "Mode local requis non support√©"]))
                return
            }
        } else {
            print("‚ùå iOS 13+ requis pour reconnaissance locale s√©curis√©e")
            handleSpeechError(NSError(domain: "SpeechRecognizer", code: -4, userInfo: [NSLocalizedDescriptionKey: "iOS 13+ requis"]))
            return
        }

        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)

        // Supprimer le tap existant s'il y en a un
        inputNode.removeTap(onBus: 0)

        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            recognitionRequest.append(buffer)
        }

        audioEngine.prepare()

        do {
            try audioEngine.start()
            print("‚úÖ Moteur audio d√©marr√© - Apple g√®re la finalisation naturellement")
        } catch {
            print("‚ùå Erreur d√©marrage audio engine: \(error)")
            handleSpeechError(error)
            return
        }

        recognitionTask = speechRecognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            self?.handleRecognitionResult(result: result, error: error, forActivation: forActivation)
        }

        // üéØ PAS DE TIMER AGRESSIF - Laisser Apple g√©rer !
        // Seulement pour l'activation continue (si utilis√©)
        if forActivation {
            DispatchQueue.main.asyncAfter(deadline: .now() + activationTimeout) { [weak self] in
                if self?.isListening == true && self?.isWaitingForQuestion != true && self?.isRecovering != true {
                    self?.restartListening(forActivation: true)
                }
            }
        }
    }

    private func handleRecognitionResult(result: SFSpeechRecognitionResult?, error: Error?, forActivation: Bool) {
        if let error = error {
            print("‚ùå Erreur reconnaissance: \(error)")

            // Pour une question ponctuelle, on g√®re diff√©remment
            if !forActivation {
                handleSingleQuestionError(error)
            } else {
                handleSpeechError(error, forActivation: forActivation)
            }
            return
        }

        guard let result = result else { return }

        let recognizedText = result.bestTranscription.formattedString.lowercased()

        print("üçé Apple dit: '\(recognizedText)' (final: \(result.isFinal))")

        // Reset des compteurs d'erreur en cas de succ√®s
        if !recognizedText.isEmpty {
            currentRetryCount = 0
            lastErrorTime = nil
        }

        DispatchQueue.main.async { [weak self] in
            self?.lastRecognizedText = recognizedText

            if forActivation {
                self?.checkForActivation(text: recognizedText)
            } else {
                if result.isFinal {
                    // Cas normal - Apple a finalis√©
                    self?.processQuestion(text: recognizedText, isFinal: true)
                } else {
                    // R√©sultat partiel - mettre √† jour et d√©marrer un timer
                    self?.lastPartialUpdate = Date()
                    self?.lastPartialResult = recognizedText
                    self?.schedulePartialResultTimeout()
                }
            }
        }
    }

    private func schedulePartialResultTimeout() {
        // Annuler tout timer pr√©c√©dent
        partialResultTimer?.invalidate()

        // D√©marrer un nouveau timer
        partialResultTimer = Timer.scheduledTimer(withTimeInterval: 1.5, repeats: false) { [weak self] _ in
            guard let self = self else { return }

            // V√©rifier si nous avons re√ßu des mises √† jour depuis
            if let lastUpdate = self.lastPartialUpdate,
               Date().timeIntervalSince(lastUpdate) >= 1.5,
               !self.lastPartialResult.isEmpty {

                print("‚ÑπÔ∏è D√©tection de fin de phrase apr√®s timeout")
                self.processQuestion(text: self.lastPartialResult, isFinal: true)
            }
        }
    }

    private func handleSingleQuestionError(_ error: Error) {
        print("‚ùå Erreur lors de la question: \(error)")

        if !lastPartialResult.isEmpty {
                print("‚ÑπÔ∏è Ignorant l'erreur car nous avons d√©j√† un r√©sultat partiel: '\(lastPartialResult)'")
                return
            }
        // Pour les questions ponctuelles, on ne fait pas de retry
        stopListening()
        isWaitingForQuestion = false

        // Message selon le type d'erreur
        if error.localizedDescription.contains("No speech detected") {
            voiceSynthesisManager?.speak("Je n'ai rien entendu")
        } else {
            voiceSynthesisManager?.speak("Erreur de reconnaissance vocale")
        }

        // ‚ñ∂Ô∏è REPRENDRE LA SYNTH√àSE VOCALE NORMALE APR√àS L'ERREUR
        DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) { [weak self] in
            self?.voiceSynthesisManager?.resumeAfterInteraction()
            print("‚ñ∂Ô∏è Synth√®se vocale normale reprise apr√®s erreur")
        }

        // Ne PAS relancer automatiquement
        lastRecognizedText = "Erreur - appui long pour r√©essayer"
    }

    // Timer d'urgence seulement (pas pour l'usage normal)
    private func handleEmergencyTimeout() {
        print("üö® TIMEOUT D'URGENCE (30s) - Quelque chose ne va pas")
        voiceSynthesisManager?.speak("Timeout d'urgence")
        finishSingleQuestion()
    }

    private func handleSpeechError(_ error: Error, forActivation: Bool = false) {
        lastErrorTime = Date()
        currentRetryCount += 1

        print("‚ùå Erreur Speech (tentative \(currentRetryCount)/\(maxRetryAttempts)): \(error)")

        // Nettoyer les ressources
        stopListening()

        // Si on d√©passe le nombre max de tentatives, arr√™ter temporairement
        if currentRetryCount >= maxRetryAttempts {
            print("üõë Trop d'erreurs, arr√™t temporaire du service vocal")
            isRecovering = true

            // Programmer une r√©cup√©ration apr√®s un d√©lai plus long
            recoveryTimer = Timer.scheduledTimer(withTimeInterval: retryDelay * 3, repeats: false) { [weak self] _ in
                self?.attemptRecovery()
            }
        } else {
            // Tentative de relance apr√®s un court d√©lai
            scheduleRetry(forActivation: forActivation)
        }
    }

    private func scheduleRetry(forActivation: Bool) {
        print("‚è≥ Programmation nouvelle tentative dans \(retryDelay)s...")
        DispatchQueue.main.asyncAfter(deadline: .now() + retryDelay) { [weak self] in
            if self?.interactionEnabled == true && self?.isRecovering != true {
                self?.startListening(forActivation: forActivation)
            }
        }
    }

    private func attemptRecovery() {
        print("üîÑ Tentative de r√©cup√©ration du service vocal...")
        isRecovering = false
        currentRetryCount = 0
        lastErrorTime = nil

        // V√©rifier la disponibilit√©
        checkSpeechAvailability()

        if interactionEnabled && speechAvailable {
            print("‚úÖ Service vocal r√©cup√©r√©, red√©marrage...")

            // Petit d√©lai avant de red√©marrer
            DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
                self?.startListening(forActivation: true)
            }
        } else {
            print("‚ùå Service vocal toujours indisponible")
        }
    }

    private func restartListening(forActivation: Bool) {
        print("üîÑ Red√©marrage √©coute...")
        stopListening()

        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            self?.startListening(forActivation: forActivation)
        }
    }

    private func checkForActivation(text: String) {
        for phrase in VoiceCommand.activationPhrases {
            if text.contains(phrase) {
                print("üéØ Phrase d'activation d√©tect√©e: '\(phrase)'")
                handleActivation()
                return
            }
        }
    }

    private func handleActivation() {
        voiceSynthesisManager?.stopSpeaking()
        playBeep()
        isWaitingForQuestion = true

        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            self?.startListening(forActivation: false)

            self?.questionTimer = Timer.scheduledTimer(withTimeInterval: self?.listeningTimeout ?? 5.0, repeats: false) { _ in
                self?.timeoutQuestion()
            }
        }
    }

    private func playBeep() {
        // ‚úÖ Logique audio intelligente (m√™me que VoiceSynthesisManager)
        let audioSession = AVAudioSession.sharedInstance()
        let hasAirPods = audioSession.currentRoute.outputs.contains {
            $0.portType == .bluetoothA2DP || $0.portType == .bluetoothHFP
        }
        
        do {
            if hasAirPods {
                try audioSession.overrideOutputAudioPort(.none) // AirPods
                print("üéß Route audio beep: AirPods")
            } else {
                try audioSession.overrideOutputAudioPort(.speaker) // Haut-parleurs
                print("üîä Route audio beep: Haut-parleurs")
            }
        } catch {
            print("‚ùå Erreur route audio beep: \(error)")
        }
        
        beepPlayer?.stop()
        beepPlayer?.currentTime = 0
        beepPlayer?.play()
        
        // üéµ Feedback selon le type de son
        if let soundURL = beepPlayer?.url {
            if soundURL.lastPathComponent.contains("custom") ||
               soundURL.lastPathComponent.contains("ecoute") ||
               soundURL.lastPathComponent.contains("activation") {
                print("üéµ Son personnalis√© d'activation jou√©: \(soundURL.lastPathComponent)")
            } else {
                print("üîä Bip d'activation g√©n√©r√© jou√©")
            }
        } else {
            print("üéµ Son d'activation jou√©")
        }
    }

    // Version modifi√©e pour g√©rer le timeout des r√©sultats partiels
    private func processQuestion(text: String, isFinal: Bool) {
        print("üìù processQuestion: '\(text)' (final: \(isFinal))")

        // Annuler le timer s'il existe
        partialResultTimer?.invalidate()
        partialResultTimer = nil

        // Annuler le timer d'urgence
        questionTimer?.invalidate()
        questionTimer = nil

        let parsedQuestion = parseQuestion(text)

        // Debug info
        let debugInfo = "Question analys√©e: Type \(parsedQuestion.type), Objet \(parsedQuestion.targetObject ?? "aucun"), \(currentImportantObjects.count) objets d√©tect√©s"
        print("üêõ \(debugInfo)")

        if !currentImportantObjects.isEmpty {
            let response = generateResponse(for: parsedQuestion)
            voiceSynthesisManager?.speak(response)
        } else {
            voiceSynthesisManager?.speak("Je ne d√©tecte aucun objet actuellement")
        }

        finishSingleQuestion()
    }

    private func finishSingleQuestion() {
        questionTimer?.invalidate()
        questionTimer = nil
        isWaitingForQuestion = false
        stopListening()

        // ‚ñ∂Ô∏è REPRENDRE LA SYNTH√àSE VOCALE NORMALE APR√àS LA QUESTION
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
            self?.voiceSynthesisManager?.resumeAfterInteraction()
            print("‚ñ∂Ô∏è Synth√®se vocale normale reprise apr√®s question")
        }

        // Message d'√©tat pour l'utilisateur
        lastRecognizedText = "Question trait√©e - appui long pour une nouvelle question"
        print("‚úÖ Question trait√©e, synth√®se normale va reprendre")
    }

    private func timeoutQuestion() {
        print("‚è∞ Timeout question - retour mode activation")
        voiceSynthesisManager?.speak("Je n'ai pas entendu de question")
        resetToActivationMode()
    }

    private func resetToActivationMode() {
        questionTimer?.invalidate()
        questionTimer = nil
        isWaitingForQuestion = false

        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
            if self?.interactionEnabled == true && self?.isRecovering != true {
                self?.startListening(forActivation: true)
            }
        }
    }

    private func stopListening() {
        partialResultTimer?.invalidate()
        partialResultTimer = nil

        if audioEngine.isRunning {
            audioEngine.stop()
        }

        audioEngine.inputNode.removeTap(onBus: 0)
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()
        recognitionRequest = nil
        recognitionTask = nil
        isListening = false

        questionTimer?.invalidate()
        questionTimer = nil
        activationTimer?.invalidate()
        activationTimer = nil

        // D√©sactiver la session audio proprement
        do {
            try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
        } catch {
            // Ignorer les erreurs de d√©sactivation - c'est normal
        }
    }

    // MARK: - Analyse des questions

    private func parseQuestion(_ text: String) -> ParsedQuestion {
        let normalizedText = text.lowercased()
            .replacingOccurrences(of: "?", with: "")
            .replacingOccurrences(of: ".", with: "")

        print("üîç PARSE: '\(text)' ‚Üí '\(normalizedText)'")

        var questionType: QuestionType = .unknown
        var confidence: Float = 0.0

        // Test des mots-cl√©s CROSSING en premier (s√©curit√© prioritaire)
        let crossingKeywords = getCrossingKeywords()
        for keyword in crossingKeywords {
            if normalizedText.contains(keyword) {
                questionType = .crossing
                confidence = 0.9
                print("‚úÖ PARSE: CROSSING d√©tect√© avec '\(keyword)' - PRIORIT√â S√âCURIT√â")
                break
            }
        }

        // Test des mots-cl√©s COUNT en deuxi√®me (plus sp√©cifique)
        if questionType == .unknown {
            let countKeywords = getCountKeywords()
            for keyword in countKeywords {
                if normalizedText.contains(keyword) {
                    questionType = .count
                    confidence = 0.8
                    print("‚úÖ PARSE: COUNT d√©tect√© avec '\(keyword)'")
                    break
                }
            }
        }

        // Si pas CROSSING ni COUNT, tester les autres
        if questionType == .unknown {
            let questionKeywords = getQuestionKeywords()
            for (type, keywords) in questionKeywords {
                if type == .crossing || type == .count { continue } // D√©j√† test√©s
                for keyword in keywords {
                    if normalizedText.contains(keyword) {
                        questionType = type
                        confidence = 0.8
                        print("‚úÖ PARSE: \(type) d√©tect√© avec '\(keyword)'")
                        break
                    }
                }
                if confidence > 0 { break }
            }
        }

        var targetObject: String?

        // Test de reconnaissance d'objet avec NOUVEAU dictionnaire complet
        for (englishObject, frenchVariants) in objectTranslations {
            for variant in frenchVariants {
                if normalizedText.contains(variant) {
                    targetObject = englishObject
                    confidence = max(confidence, 0.7)
                    print("‚úÖ PARSE: Objet '\(variant)' ‚Üí '\(englishObject)'")
                    break
                }
            }
            if targetObject != nil { break }
        }

        // Cas sp√©ciaux
        if normalizedText.contains("sc√®ne") || normalizedText.contains("situation") {
            questionType = .sceneOverview
            confidence = 0.9
            print("‚úÖ PARSE: sc√®ne/situation d√©tect√©")
        }

        if normalizedText.contains("devant") {
            questionType = .description
            confidence = max(confidence, 0.8)
            print("‚úÖ PARSE: devant d√©tect√©")
        }

        let result = ParsedQuestion(
            type: questionType,
            targetObject: targetObject,
            confidence: confidence,
            originalText: text
        )

        print("üìã PARSE FINAL: Type=\(questionType), Objet=\(targetObject ?? "aucun"), Conf=\(confidence)")

        return result
    }

    // MARK: - G√©n√©ration des r√©ponses

    private func generateResponse(for question: ParsedQuestion) -> String {
        print("üí¨ G√©n√©ration r√©ponse pour: '\(question.originalText)'")
        print("   - Type: \(question.type), Objet: \(question.targetObject ?? "aucun")")

        let analysis = analyzeCurrentScene()

        let response: String
        switch question.type {
        case .presence:
            response = handlePresenceQuestion(question, analysis: analysis)
        case .count:
            response = handleCountQuestion(question, analysis: analysis)
        case .location:
            response = handleLocationQuestion(question, analysis: analysis)
        case .description:
            response = handleDescriptionQuestion(analysis: analysis)
        case .sceneOverview:
            response = handleSceneOverviewQuestion(analysis: analysis)
        case .crossing:
            response = handleCrossingQuestion(analysis: analysis)
        case .specific:
            response = handleSpecificQuestion(question, analysis: analysis)
        case .unknown:
            response = handleUnknownQuestion(question, analysis: analysis)
        }

        print("üí¨ R√©ponse: '\(response)'")
        return response
    }

    private func analyzeCurrentScene() -> SceneAnalysis {
        print("üìä Analyse de sc√®ne avec \(currentImportantObjects.count) objets importants")

        var objectsByType: [String: Int] = [:]
        var objectsByZone: [String: [String]] = [
            "devant": [], "gauche": [], "droite": []
        ]
        var distances: [String: Float] = [:]
        var criticalObjects: [String] = []
        var navigationObjects: [String] = []

        for (index, item) in currentImportantObjects.enumerated() {
            let object = item.object
            let frenchLabel = translateToFrench(object.label)

            print("   \(index + 1). #\(object.trackingNumber) \(object.label) ‚Üí \(frenchLabel) (score: \(item.score))")

            // Compter par type
            objectsByType[frenchLabel, default: 0] += 1

            // Analyser la position
            let zone = getZoneFromBoundingBox(object.lastRect)
            objectsByZone[zone, default: []].append(frenchLabel)

            // Distance
            if let distance = object.distance {
                let key = "\(frenchLabel)_\(object.trackingNumber)"
                distances[key] = distance
                print("     ‚Üí Distance: \(distance)m")
            }

            // Objets critiques
            if item.score > 0.7 {
                criticalObjects.append(frenchLabel)
            }

            // Objets de navigation
            if ["traffic_light", "traffic_sign", "crosswalk", "street_light", "traffic_cone"].contains(object.label) {
                navigationObjects.append(frenchLabel)
            }
        }

        print("üìä R√©sum√© par type:")
        for (type, count) in objectsByType {
            print("   - \(type): \(count)")
        }

        print("üìä R√©sum√© par zone:")
        for (zone, objects) in objectsByZone {
            if !objects.isEmpty {
                print("   - \(zone): \(objects)")
            }
        }

        return SceneAnalysis(
            totalObjects: currentImportantObjects.count,
            objectsByType: objectsByType,
            objectsByZone: objectsByZone,
            distances: distances,
            criticalObjects: criticalObjects,
            navigationObjects: navigationObjects
        )
    }

    private func handlePresenceQuestion(_ question: ParsedQuestion, analysis: SceneAnalysis) -> String {
        print("‚ùì Traitement question PRESENCE:")

        guard let targetObject = question.targetObject else {
            print("   - Aucun objet sp√©cifique ‚Üí pr√©sence g√©n√©rale")
            
            if analysis.totalObjects == 0 {
                return "Non, aucun objet d√©tect√© actuellement"
            }
            
            // Cr√©er une liste des objets d√©tect√©s avec leurs quantit√©s
            let objectsList = analysis.objectsByType.map { type, count in
                if count == 1 {
                    return "une \(type)"
                } else {
                    return "\(count) \(type)s"
                }
            }
            
            if objectsList.count == 1 {
                return "Oui, je d√©tecte \(objectsList[0])"
            } else if objectsList.count == 2 {
                return "Oui, je d√©tecte \(objectsList[0]) et \(objectsList[1])"
            } else {
                let allButLast = objectsList.dropLast().joined(separator: ", ")
                return "Oui, je d√©tecte \(allButLast) et \(objectsList.last!)"
            }
        }

        let frenchLabel = translateToFrench(targetObject)
        let count = analysis.objectsByType[frenchLabel] ?? 0

        print("   - Objet recherch√©: '\(targetObject)' ‚Üí '\(frenchLabel)'")
        print("   - Pr√©sence: \(count > 0 ? "OUI (\(count))" : "NON")")
        print("   - Objets disponibles: \(Array(analysis.objectsByType.keys))")

        if count > 0 {
            let location = findObjectLocation(targetObject, in: analysis)
            return count == 1 ?
                "Oui, je vois une \(frenchLabel)\(location.isEmpty ? "" : " \(location)")" :
                "Oui, je vois \(count) \(frenchLabel)s"
        } else {
            return "Non, je ne vois pas de \(frenchLabel) actuellement"
        }
    }

    private func handleCountQuestion(_ question: ParsedQuestion, analysis: SceneAnalysis) -> String {
        guard let targetObject = question.targetObject else {
            let total = analysis.totalObjects
            if total == 0 {
                return "Je ne d√©tecte aucun objet actuellement"
            } else if total == 1 {
                return "Je d√©tecte un objet"
            } else {
                let summaryParts = analysis.objectsByType.map { type, count in
                    "\(count) \(type)\(count > 1 ? "s" : "")"
                }
                let summary = summaryParts.joined(separator: ", ")
                return "Je d√©tecte \(total) objets au total : \(summary)"
            }
        }

        let frenchLabel = translateToFrench(targetObject)
        let count = analysis.objectsByType[frenchLabel] ?? 0

        switch count {
        case 0:
            return "Aucune \(frenchLabel) d√©tect√©e"
        case 1:
            return "Une \(frenchLabel)"
        default:
            return "\(count) \(frenchLabel)s"
        }
    }

    private func handleLocationQuestion(_ question: ParsedQuestion, analysis: SceneAnalysis) -> String {
        guard let targetObject = question.targetObject else {
            return generateGeneralLocationResponse(analysis: analysis)
        }

        let frenchLabel = translateToFrench(targetObject)
        let count = analysis.objectsByType[frenchLabel] ?? 0

        if count == 0 {
            return "Je ne vois pas de \(frenchLabel) actuellement"
        }

        let location = findObjectLocation(targetObject, in: analysis)
        let distance = findObjectDistance(targetObject, in: analysis)

        var response = "La \(frenchLabel) est \(location.isEmpty ? "visible" : location)"
        if !distance.isEmpty {
            response += " \(distance)"
        }

        if count > 1 {
            response = "Je vois \(count) \(frenchLabel)s. " + response.replacingOccurrences(of: "La \(frenchLabel)", with: "L'une d'elles")
        }

        return response
    }

    private func handleDescriptionQuestion(analysis: SceneAnalysis) -> String {
        if analysis.totalObjects == 0 {
            return "Je ne vois rien de particulier devant vous"
        }

        let frontObjects = analysis.objectsByZone["devant"] ?? []

        if frontObjects.isEmpty {
            return "Rien directement devant vous, mais je d√©tecte des objets sur les c√¥t√©s"
        }

        let objectGroups = Dictionary(grouping: frontObjects) { $0 }
        let objectList = objectGroups.map { obj, occurrences in
            let count = occurrences.count
            return count > 1 ? "\(count) \(obj)s" : "une \(obj)"
        }.joined(separator: ", ")

        return "Devant vous, je vois : \(objectList)"
    }

    private func handleSceneOverviewQuestion(analysis: SceneAnalysis) -> String {
        if analysis.totalObjects == 0 {
            return "Aucun objet d√©tect√©"
        }

        let plansAnalysis = analyzeSceneByPlans()
        var description: [String] = []

        // üéØ Premier plan - Les √©l√©ments proches et critiques
        if !plansAnalysis.firstPlan.isEmpty {
            let firstPlanDesc = createDirectDescription(plansAnalysis.firstPlan, plan: "premier")
            description.append("Proche : \(firstPlanDesc)")
        }

        // üéØ Deuxi√®me plan - Les √©l√©ments moyens
        if !plansAnalysis.secondPlan.isEmpty {
            let secondPlanDesc = createDirectDescription(plansAnalysis.secondPlan, plan: "deuxi√®me")
            description.append("Moyen : \(secondPlanDesc)")
        }

        // üéØ Troisi√®me plan - Les √©l√©ments lointains
        if !plansAnalysis.thirdPlan.isEmpty {
            let thirdPlanDesc = createDirectDescription(plansAnalysis.thirdPlan, plan: "troisi√®me")
            description.append("Loin : \(thirdPlanDesc)")
        }

        // üåü Ajout d'information d'ambiance
        let ambiance = determineAmbiance(analysis)
        if !ambiance.isEmpty {
            description.append(ambiance)
        }

        let result = description.isEmpty ?
            "\(analysis.totalObjects) objet\(analysis.totalObjects > 1 ? "s" : "") d√©tect√©\(analysis.totalObjects > 1 ? "s" : "")" :
            description.joined(separator: ". ")

        return result
    }

    // MARK: - Analyse par plans
    
    private struct PlansAnalysis {
        let firstPlan: [ObjectDescription]      // < 3m - √©l√©ments proches
        let secondPlan: [ObjectDescription]     // 3-8m - √©l√©ments moyens
        let thirdPlan: [ObjectDescription]      // > 8m - √©l√©ments lointains
    }
    
    private struct ObjectDescription {
        let frenchName: String
        let distance: Float?
        let zone: String
        let count: Int
        let isCritical: Bool
        let isNavigation: Bool
    }
    
    private func analyzeSceneByPlans() -> PlansAnalysis {
        var firstPlan: [ObjectDescription] = []
        var secondPlan: [ObjectDescription] = []
        var thirdPlan: [ObjectDescription] = []
        
        // Grouper les objets par type et analyser leurs distances
        let objectGroups = Dictionary(grouping: currentImportantObjects) {
            translateToFrench($0.object.label)
        }
        
        for (frenchName, objects) in objectGroups {
            let distances = objects.compactMap { $0.object.distance }
            let avgDistance = distances.isEmpty ? nil : distances.reduce(0, +) / Float(distances.count)
            let minDistance = distances.min()
            
            // D√©terminer la zone principale
            let zones = objects.map { getZoneFromBoundingBox($0.object.lastRect) }
            let zoneCounts = Dictionary(grouping: zones, by: { $0 }).mapValues { $0.count }
            let mainZone = zoneCounts.max(by: { $0.value < $1.value })?.key ?? "devant"
            
            // V√©rifier criticit√© et navigation
            let isCritical = objects.contains { $0.score > 0.7 }
            let isNavigation = objects.contains {
                ["traffic_light", "traffic_sign", "crosswalk", "street_light", "traffic_cone"].contains($0.object.label)
            }
            
            let objectDesc = ObjectDescription(
                frenchName: frenchName,
                distance: avgDistance,
                zone: mainZone,
                count: objects.count,
                isCritical: isCritical,
                isNavigation: isNavigation
            )
            
            // Classer par plan selon la distance
            if let minDist = minDistance {
                if minDist < 3.0 {
                    firstPlan.append(objectDesc)
                } else if minDist < 8.0 {
                    secondPlan.append(objectDesc)
                } else {
                    thirdPlan.append(objectDesc)
                }
            } else {
                // Sans distance, classer par priorit√©
                if isCritical {
                    firstPlan.append(objectDesc)
                } else {
                    secondPlan.append(objectDesc)
                }
            }
        }
        
        return PlansAnalysis(
            firstPlan: firstPlan.sorted { $0.distance ?? 0 < $1.distance ?? 0 },
            secondPlan: secondPlan.sorted { $0.distance ?? 5 < $1.distance ?? 5 },
            thirdPlan: thirdPlan.sorted { $0.distance ?? 10 < $1.distance ?? 10 }
        )
    }
    
    private func createDirectDescription(_ objects: [ObjectDescription], plan: String) -> String {
        if objects.isEmpty { return "" }
        
        var descriptions: [String] = []
        
        for obj in objects {
            let directName = getDirectName(obj)
            let spatialInfo = createSpatialInfo(obj, plan: plan)
            
            if obj.count == 1 {
                descriptions.append("\(directName)\(spatialInfo)")
            } else {
                descriptions.append("\(obj.count) \(obj.frenchName)s\(spatialInfo)")
            }
        }
        
        return joinDescriptions(descriptions)
    }
    
    private func getDirectName(_ obj: ObjectDescription) -> String {
        let directNames: [String: String] = [
            "voiture": "une voiture",
            "personne": "une personne",
            "arbre": "un arbre",
            "b√¢timent": "un b√¢timent",
            "poteau": "un poteau",
            "feu de circulation": "un feu",
            "panneau de signalisation": "un panneau",
            "trottoir": "le trottoir",
            "route": "la route",
            "passage pi√©ton": "un passage pi√©ton",
            "lampadaire": "un lampadaire",
            "banc": "un banc",
            "v√©g√©tation": "de la v√©g√©tation",
            "mur": "un mur",
            "eau": "de l'eau"
        ]
        
        return directNames[obj.frenchName] ?? "une \(obj.frenchName)"
    }
    
    private func createSpatialInfo(_ obj: ObjectDescription, plan: String) -> String {
        var spatial = ""
        
        // Position spatiale directe
        switch obj.zone {
        case "gauche":
            spatial += " √† gauche"
        case "droite":
            spatial += " √† droite"
        case "devant":
            spatial += " devant vous"
        default:
            spatial += ""
        }
        
        // Distance simple
        if let distance = obj.distance {
            if distance < 2.0 {
                spatial += ", tr√®s proche"
            } else if distance < 5.0 {
                spatial += ", proche"
            } else {
                spatial += ", plus loin"
            }
        }
        
        return spatial
    }
    
    private func joinDescriptions(_ descriptions: [String]) -> String {
        if descriptions.isEmpty { return "" }
        if descriptions.count == 1 { return descriptions[0] }
        if descriptions.count == 2 { return "\(descriptions[0]) et \(descriptions[1])" }
        
        let allButLast = descriptions.dropLast().joined(separator: ", ")
        return "\(allButLast) et \(descriptions.last!)"
    }
    
    private func determineAmbiance(_ analysis: SceneAnalysis) -> String {
        // Ambiances plus directes
        if analysis.criticalObjects.count > 2 {
            return "Attention, plusieurs objets proches"
        }
        
        if analysis.navigationObjects.count > 0 {
            return "Signalisation pr√©sente"
        }
        
        let vehicleCount = analysis.objectsByType.filter {
            ["voiture", "camion", "bus", "moto"].contains($0.key)
        }.values.reduce(0, +)
        
        if vehicleCount > 3 {
            return "Circulation dense"
        }
        
        if analysis.totalObjects < 3 {
            return "Environnement calme"
        }
        
        return ""
    }

    private func handleSpecificQuestion(_ question: ParsedQuestion, analysis: SceneAnalysis) -> String {
        return handleLocationQuestion(question, analysis: analysis)
    }

    private func handleCrossingQuestion(analysis: SceneAnalysis) -> String {
        print("‚ùì Traitement question TRAVERS√âE:")
        
        // 1. Analyser la signalisation de travers√©e
        let crossingSignalization = analyzeCrossingSignalization(analysis)
        
        // 2. Analyser la circulation
        let trafficAnalysis = analyzeTrafficSituation(analysis)
        
        // 3. G√©n√©rer la r√©ponse selon la situation
        return generateCrossingAdvice(signalization: crossingSignalization, traffic: trafficAnalysis)
    }
    
    private struct CrossingSignalization {
        let hasTrafficLight: Bool
        let hasCrosswalk: Bool
        let hasTrafficSigns: Bool
        let hasStreetLight: Bool
        let signalizationScore: Int
    }
    
    private struct TrafficSituation {
        let vehicleCount: Int
        let closeVehicles: Int
        let movingVehicles: Int
        let safetyScore: Int
    }
    
    private func analyzeCrossingSignalization(_ analysis: SceneAnalysis) -> CrossingSignalization {
        var hasTrafficLight = false
        var hasCrosswalk = false
        var hasTrafficSigns = false
        var hasStreetLight = false
        
        // V√©rifier la pr√©sence d'√©l√©ments de signalisation
        for (object, _) in currentImportantObjects {
            switch object.label {
            case "traffic_light":
                hasTrafficLight = true
            case "crosswalk":
                hasCrosswalk = true
            case "traffic_sign":
                hasTrafficSigns = true
            case "street_light":
                hasStreetLight = true
            default:
                break
            }
        }
        
        // Calculer un score de signalisation (0-4)
        var score = 0
        if hasTrafficLight { score += 2 }  // Feu = tr√®s important
        if hasCrosswalk { score += 2 }     // Passage pi√©ton = tr√®s important
        if hasTrafficSigns { score += 1 }  // Panneaux = utiles
        if hasStreetLight { score += 1 }   // √âclairage = s√©curit√©
        
        print("   - Signalisation: Feu=\(hasTrafficLight), Passage=\(hasCrosswalk), Panneaux=\(hasTrafficSigns), Score=\(score)")
        
        return CrossingSignalization(
            hasTrafficLight: hasTrafficLight,
            hasCrosswalk: hasCrosswalk,
            hasTrafficSigns: hasTrafficSigns,
            hasStreetLight: hasStreetLight,
            signalizationScore: score
        )
    }
    
    private func analyzeTrafficSituation(_ analysis: SceneAnalysis) -> TrafficSituation {
        let vehicleTypes = ["voiture", "camion", "bus", "moto", "v√©lo"]
        var vehicleCount = 0
        var closeVehicles = 0
        var movingVehicles = 0
        
        for (object, score) in currentImportantObjects {
            let frenchLabel = translateToFrench(object.label)
            
            if vehicleTypes.contains(frenchLabel) {
                vehicleCount += 1
                
                // V√©hicules proches (< 5m)
                if let distance = object.distance, distance < 5.0 {
                    closeVehicles += 1
                }
                
                // V√©hicules en mouvement (score √©lev√© souvent = mouvement)
                if score > 0.8 {
                    movingVehicles += 1
                }
            }
        }
        
        // Score de s√©curit√© (0-10, 10 = tr√®s s√ªr)
        var safetyScore = 10
        safetyScore -= closeVehicles * 3    // -3 par v√©hicule proche
        safetyScore -= movingVehicles * 2   // -2 par v√©hicule en mouvement
        safetyScore -= max(0, vehicleCount - 2) // P√©nalit√© si beaucoup de v√©hicules
        safetyScore = max(0, safetyScore)   // Minimum 0
        
        print("   - Circulation: Total=\(vehicleCount), Proches=\(closeVehicles), Mouvement=\(movingVehicles), S√©curit√©=\(safetyScore)/10")
        
        return TrafficSituation(
            vehicleCount: vehicleCount,
            closeVehicles: closeVehicles,
            movingVehicles: movingVehicles,
            safetyScore: safetyScore
        )
    }
    
    private func generateCrossingAdvice(signalization: CrossingSignalization, traffic: TrafficSituation) -> String {
        print("   - G√©n√©ration conseil travers√©e...")
        
        // Cas 1: Signalisation compl√®te (feu + passage pi√©ton)
        if signalization.hasTrafficLight && signalization.hasCrosswalk {
            if traffic.safetyScore >= 7 {
                return "Oui, signalisation compl√®te pr√©sente. Traversez au feu vert avec prudence"
            } else if traffic.closeVehicles > 0 {
                return "Signalisation pr√©sente mais circulation dense. Attendez que les v√©hicules passent"
            } else {
                return "Signalisation pr√©sente. V√©rifiez le feu et traversez prudemment"
            }
        }
        
        // Cas 2: Passage pi√©ton sans feu
        if signalization.hasCrosswalk && !signalization.hasTrafficLight {
            if traffic.safetyScore >= 8 {
                return "Passage pi√©ton d√©tect√©, circulation calme. Vous pouvez traverser prudemment"
            } else if traffic.closeVehicles > 2 {
                return "Passage pi√©ton pr√©sent mais circulation dense. Attendez une accalmie"
            } else {
                return "Passage pi√©ton pr√©sent. V√©rifiez bien la circulation avant de traverser"
            }
        }
        
        // Cas 3: Feu sans passage pi√©ton visible
        if signalization.hasTrafficLight && !signalization.hasCrosswalk {
            return "Feu de circulation d√©tect√©. Cherchez le passage pi√©ton √† proximit√©"
        }
        
        // Cas 4: Signalisation minimale ou absente
        if signalization.signalizationScore <= 1 {
            if traffic.vehicleCount == 0 {
                return "Aucune signalisation et aucun v√©hicule"
            } else if traffic.safetyScore >= 8 {
                return "Pas de signalisation officielle. Circulation calme mais restez tr√®s prudent"
            } else {
                return "Pas de signalisation s√©curis√©e et circulation pr√©sente. Cherchez un passage am√©nag√©"
            }
        }
        
        // Cas 5: Signalisation partielle
        if traffic.safetyScore >= 6 {
            return "Signalisation partielle, circulation mod√©r√©e. Travers√©e possible avec grande prudence"
        } else {
            return "Signalisation insuffisante et circulation dense. Trouvez un passage plus s√ªr"
        }
    }

    private func handleUnknownQuestion(_ question: ParsedQuestion, analysis: SceneAnalysis) -> String {
        let text = question.originalText.lowercased()

        if text.contains("aide") || text.contains("help") {
            return "Vous pouvez me demander s'il y a des objets, combien il y en a, o√π ils sont, si vous pouvez traverser, ou me demander de d√©crire la sc√®ne"
        }

        if analysis.totalObjects == 0 {
            return "Je ne d√©tecte aucun objet actuellement. Reformulez votre question si besoin"
        }

        let mainObjectsList = Array(analysis.objectsByType.prefix(3))
        let mainObjects = mainObjectsList.map { type, count in
            "\(count) \(type)\(count > 1 ? "s" : "")"
        }.joined(separator: ", ")

        return "Je ne suis pas s√ªr de comprendre. Actuellement je vois : \(mainObjects)"
    }

    // MARK: - M√©thodes utilitaires

    private func translateToFrench(_ englishLabel: String) -> String {
        for (english, frenchVariants) in objectTranslations {
            if english == englishLabel {
                return frenchVariants.first ?? englishLabel
            }
        }
        return englishLabel
    }

    private func getZoneFromBoundingBox(_ rect: CGRect) -> String {
        let centerX = rect.midX

        if centerX < 0.3 {
            return "gauche"
        } else if centerX > 0.7 {
            return "droite"
        } else {
            return "devant"
        }
    }

    private func findObjectLocation(_ objectType: String, in analysis: SceneAnalysis) -> String {
        let frenchLabel = translateToFrench(objectType)

        for (zone, objects) in analysis.objectsByZone {
            if objects.contains(frenchLabel) {
                return "√† \(zone == "devant" ? "votre avant" : zone)"
            }
        }
        return ""
    }

    private func findObjectDistance(_ objectType: String, in analysis: SceneAnalysis) -> String {
        let frenchLabel = translateToFrench(objectType)
        var closestDistance: Float?

        for (key, distance) in analysis.distances {
            if key.contains(frenchLabel) {
                if closestDistance == nil || distance < closestDistance! {
                    closestDistance = distance
                }
            }
        }

        guard let distance = closestDistance else { return "" }

        if distance < 1.0 {
            return "√† \(Int(distance * 100)) centim√®tres"
        } else if distance < 10.0 {
            return "√† \(String(format: "%.1f", distance)) m√®tres"
        } else {
            return "√† \(Int(distance)) m√®tres"
        }
    }

    private func generateGeneralLocationResponse(analysis: SceneAnalysis) -> String {
        if analysis.totalObjects == 0 {
            return "Aucun objet d√©tect√© pour localiser"
        }

        var locations: [String] = []

        for (zone, objects) in analysis.objectsByZone {
            if !objects.isEmpty {
                let count = objects.count
                let zoneDescription = zone == "devant" ? "devant vous" : "√† \(zone)"
                locations.append("\(count) objet\(count > 1 ? "s" : "") \(zoneDescription)")
            }
        }

        return locations.isEmpty ? "Objets d√©tect√©s sans position pr√©cise" : locations.joined(separator: ", ")
    }

    // MARK: - Interface publique pour les stats

    func getStats() -> String {
        let statusText: String

        if isRecovering {
            statusText = "üîÑ R√©cup√©ration en cours"
        } else if isListening {
            statusText = isWaitingForQuestion ? "üé§ √âcoute d'une question" : "üëÇ √âcoute active"
        } else if interactionEnabled {
            statusText = "‚úÖ Pr√™t (touchez le micro pour parler)"
        } else {
            statusText = "‚ùå Non disponible"
        }

        let errorInfo = currentRetryCount > 0 ? "\n‚ö†Ô∏è Erreurs r√©centes: \(currentRetryCount)/\(maxRetryAttempts)" : ""

        // Mode de reconnaissance (toujours local)
        var privacyInfo = "üîí Mode: LOCAL uniquement (100% priv√©)"
        if #available(iOS 13.0, *) {
            if let speechRecognizer = speechRecognizer {
                if !speechRecognizer.supportsOnDeviceRecognition {
                    privacyInfo = "‚ùå Mode local non support√© (interaction d√©sactiv√©e)"
                }
            }
        } else {
            privacyInfo = "‚ùå iOS 13+ requis pour mode local"
        }

        // Info sur le son d'activation
        var soundInfo = "üéµ Son d'activation: "
        if let soundURL = beepPlayer?.url {
            if soundURL.lastPathComponent.contains("custom") ||
               soundURL.lastPathComponent.contains("ecoute") ||
               soundURL.lastPathComponent.contains("activation") {
                soundInfo += "Personnalis√© (\(soundURL.lastPathComponent))"
            } else {
                soundInfo += "Bip g√©n√©r√©"
            }
        } else {
            soundInfo += "Non charg√©"
        }

        return """
        üé§ Interaction Vocale - AIDE √Ä LA TRAVERS√âE + DICTIONNAIRE COMPLET:
           - √âtat: \(statusText)
           - Service: \(speechAvailable ? "‚úÖ Disponible" : "‚ùå Indisponible")
           - \(privacyInfo)
           - \(soundInfo)
           - Derni√®re activit√©: "\(lastRecognizedText)"
           - Objets analys√©s: \(currentImportantObjects.count)
           - Dictionnaire d'objets: \(objectTranslations.count) types support√©s\(errorInfo)

        üìö Nouveaux objets support√©s:
           ‚Ä¢ Infrastructure: trottoir, passage pi√©ton, piste cyclable, voie ferr√©e
           ‚Ä¢ Mobilier urbain: banc, poubelle, parcm√®tre, support v√©los
           ‚Ä¢ Barri√®res: mur, cl√¥ture, glissi√®re de s√©curit√©, barri√®re temporaire
           ‚Ä¢ Signalisation: lampadaire, c√¥nes, panneaux
           ‚Ä¢ V√©hicules: v√©hicule lent, groupe v√©hicules, v√©hicule ferroviaire
           ‚Ä¢ Environnement: v√©g√©tation, eau, terrain, b√¢timent, pont

        üö¶ NOUVELLE QUESTION - "Est-ce que je peux traverser ?":
           ‚Ä¢ Analyse automatique de la signalisation (feux, passages pi√©tons, panneaux)
           ‚Ä¢ √âvaluation de la circulation (nombre, proximit√©, mouvement des v√©hicules)
           ‚Ä¢ Conseils adaptatifs selon la situation:
             - "Oui, signalisation compl√®te pr√©sente. Traversez au feu vert avec prudence"
             - "Passage pi√©ton pr√©sent mais circulation dense. Attendez une accalmie"
             - "Pas de signalisation s√©curis√©e. Cherchez un passage am√©nag√©"

        üé® DESCRIPTION PAR PLANS - Version directe et claire:
           ‚Ä¢ Proche (< 3m): "Proche : une voiture devant vous, tr√®s proche"
           ‚Ä¢ Moyen (3-8m): "Moyen : un lampadaire √† gauche"  
           ‚Ä¢ Loin (> 8m): "Loin : un b√¢timent"
           ‚Ä¢ Exemple complet: "Proche : une voiture devant vous, tr√®s proche. Moyen : un lampadaire √† gauche et un banc √† droite. Signalisation pr√©sente"

        üí° Mode d'emploi:
           1. Appui long sur l'√©cran (0.8s)
           2. Attendez le son d'activation üéµ
           3. Posez votre question clairement
           4. Apple g√®re automatiquement la finalisation

        ‚ùì Questions support√©es (avec tous les nouveaux objets):
           - "Y a-t-il un lampadaire ?"
           - "Combien de c√¥nes ?"
           - "O√π est le passage pi√©ton ?"
           - "Y a-t-il de la v√©g√©tation ?"
           - "Est-ce que je peux traverser ?" ‚Üê NOUVELLE QUESTION INTELLIGENTE üö¶
           - "D√©cris la sc√®ne" ‚Üê DESCRIPTION PAR PLANS ‚ú®

        üîí Confidentialit√© garantie:
           - Aucune donn√©e audio envoy√©e sur internet
           - Traitement 100% local sur votre appareil
           - Pas d'√©coute continue (√©conomie batterie)

        üçé Syst√®me Apple:
           - D√©tection automatique des pauses
           - Finalisation intelligente des phrases
           - Timeout d'urgence: 30s (vs 8s avant)
        """
    }

    /// Indique si le service est pr√™t √† traiter une question
    func isReadyForQuestion() -> Bool {
        return interactionEnabled && speechAvailable && !isListening && !isRecovering
    }
}
